# import os
# import io
# import re
# import base64
# import numpy as np
# from flask import Flask, render_template, request, redirect, url_for, session, jsonify
# import mysql.connector
# import os
#
#
# EMBEDDING_MODEL = "text-embedding-004"
# # üîë C·∫§U H√åNH API KEY (Thay b·∫±ng key th·∫≠t c·ªßa b·∫°n)
# # LangChain/Google SDK s·∫Ω ƒë·ªçc bi·∫øn n√†y
# os.environ["GOOGLE_API_KEY"] = "AIzaSyDMV72De3esk0KpzpLLEo7PJRWTnwM8vr8"
# VECTOR_STORE = None # Bi·∫øn to√†n c·ª•c ch·ª©a c∆° s·ªü d·ªØ li·ªáu vector
# # --- C·∫¶N C√ÄI ƒê·∫∂T: pip install flask tensorflow pillow numpy mysql-connector-python ---
# try:
#     import tensorflow as tf
#     from tensorflow.keras.preprocessing import image
# except ImportError:
#     print("!!! L·ªñI: Thi·∫øu th∆∞ vi·ªán AI. Vui l√≤ng c√†i ƒë·∫∑t: pip install tensorflow")
#
# # =================================================================
# # 1. C·∫§U H√åNH DATABASE
# # =================================================================
# DB_CONFIG = {
#     'host': 'localhost',
#     'user': 'root',
#     'password': '123456',
#     'database': 'benh_ga'
# }
#
#
# # --- H√ÄM K·∫æT N·ªêI DATABASE ---
# def get_db_connection():
#     """Thi·∫øt l·∫≠p k·∫øt n·ªëi v·ªõi MySQL"""
#     try:
#         conn = mysql.connector.connect(**DB_CONFIG)
#         return conn
#     except mysql.connector.Error as err:
#         print(f"L·ªói k·∫øt n·ªëi database: {err}")
#         return None
#
#
# # =================================================================
# # 2. C·∫§U H√åNH V√Ä T·∫¢I M√î H√åNH AI
# # =================================================================
#
# # ƒê∆Ø·ªúNG D·∫™N M√î H√åNH C·ª¶A B·∫†N
# MODEL_PATH = r'D:\Hoc Ki Cuoi\Capstone-project-VKU\Web_Final_ok\model\best_model.keras'
#
# # T√™n 4 l·ªõp b·ªánh (PH·∫¢I ƒê√öNG TH·ª® T·ª∞ ABC)
# CLASS_NAMES = ['Coccidiosis', 'Healthy', 'New Castle Disease', 'Salmonella']
# # K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o
# IMG_HEIGHT = 224
# IMG_WIDTH = 224
#
# app = Flask(__name__)
# # KHAI B√ÅO KEY B√ç M·∫¨T CHO SESSION (B·∫Øt bu·ªôc)
# app.secret_key = 'mot_chuoi_bi_mat_rat_dai_va_kho'
#
# # T·∫¢I M√î H√åNH (Ch·ªâ 1 l·∫ßn)
# model = None
# try:
#     if tf is not None:
#         model = tf.keras.models.load_model(MODEL_PATH)
#         print(f">>> ‚úÖ M√¥ h√¨nh AI ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng t·ª´: {MODEL_PATH}")
# except Exception as e:
#     print(f"!!! L·ªñI: Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh t·ª´ ƒë∆∞·ªùng d·∫´n: {MODEL_PATH}")
#     print(f"L·ªói chi ti·∫øt: {e}")
#     print("Ch·ª©c nƒÉng ch·∫©n ƒëo√°n AI s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")
#
#
# # -------------------------------------------------------------------------
# ## --- H√ÄM TI·ªÄN X·ª¨ L√ù ·∫¢NH (D√ôNG CHO CH·∫®N ƒêO√ÅN AI) ---
# # -------------------------------------------------------------------------
# def process_and_predict(base64_img_string):
#     """X·ª≠ l√Ω chu·ªói base64 th√†nh ·∫£nh, chu·∫©n h√≥a v√† ƒë∆∞a ra d·ª± ƒëo√°n."""
#     if model is None:
#         return "L·ªói t·∫£i m√¥ h√¨nh", 0.0
#
#     try:
#         # X√≥a ph·∫ßn header base64 (v√≠ d·ª•: data:image/jpeg;base64,)
#         img_data = re.sub('^data:image/.+;base64,', '', base64_img_string)
#         img_bytes = base64.b64decode(img_data)
#
#         # Chuy·ªÉn bytes th√†nh ·∫£nh v√† resize
#         img = image.load_img(io.BytesIO(img_bytes), target_size=(IMG_HEIGHT, IMG_WIDTH))
#
#         # Chu·∫©n b·ªã cho m√¥ h√¨nh
#         x = image.img_to_array(img)
#         x = np.expand_dims(x, axis=0)
#
#         # CHU·∫®N H√ìA (Ph·∫£i kh·ªõp v·ªõi qu√° tr√¨nh hu·∫•n luy·ªán)
#         x = x / 255.0
#
#         # D·ª± ƒëo√°n
#         predictions = model.predict(x)
#
#         # L·∫•y k·∫øt qu·∫£
#         predicted_class_index = np.argmax(predictions[0])
#         confidence = np.max(predictions[0]) * 100
#         predicted_class_name = CLASS_NAMES[predicted_class_index]
#
#         return predicted_class_name, confidence
#
#     except Exception as e:
#         print(f"L·ªñI x·ª≠ l√Ω ·∫£nh/d·ª± ƒëo√°n: {e}")
#         return "L·ªói x·ª≠ l√Ω", 0.0
#
#
# # =================================================================
# # 3. ƒê·ªäNH TUY·∫æN (ROUTES) ·ª®NG D·ª§NG
# # =================================================================
#
# ## --- ROUTE ƒêƒÇNG NH·∫¨P (Login) ---
# @app.route('/', methods=['GET', 'POST'])
# @app.route('/login', methods=['GET', 'POST'])
# def login_page():
#     error_message = None
#     if request.method == 'POST':
#         taikhoan = request.form.get('taikhoan')
#         mk = request.form.get('mk')
#
#         conn = get_db_connection()
#         if conn:
#             cursor = conn.cursor(dictionary=True)
#             query = "SELECT * FROM user WHERE taikhoan = %s AND matkhau = %s"
#             cursor.execute(query, (taikhoan, mk))
#             user = cursor.fetchone()
#
#             cursor.close()
#             conn.close()
#
#             if user:
#                 session['loggedin'] = True
#                 session['username'] = user.get('taikhoan')
#                 return redirect(url_for('trangchu_page'))
#             else:
#                 error_message = 'T√†i kho·∫£n ho·∫∑c m·∫≠t kh·∫©u kh√¥ng ƒë√∫ng.'
#         else:
#             error_message = 'L·ªói k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh DB.'
#
#     # Hi·ªÉn th·ªã trang login
#     return render_template('login.html', error=error_message)
#
#
# ## --- ROUTE TRANG CH·ª¶ (Sau khi ƒëƒÉng nh·∫≠p) ---
# @app.route('/trangchu')
# def trangchu_page():
#     # B·∫£o v·ªá trang
#     if 'loggedin' not in session:
#         return redirect(url_for('login_page'))
#
#     return render_template('trangchu.html', username=session.get('username'))
#
#
# ## --- ROUTE PH√ÇN LO·∫†I B·ªÜNH G√Ä (Form t·∫£i ·∫£nh) ---
# @app.route('/phan_loai_benh_ga')
# def phan_loai_benh_ga_page():
#     # B·∫£o v·ªá trang
#     if 'loggedin' not in session:
#         return redirect(url_for('login_page'))
#
#     # Trang n√†y ch·ª©a form HTML/JS ƒë·ªÉ g·ª≠i ·∫£nh l√™n API /diagnose
#     return render_template('phan_loai_benh_ga.html', username=session.get('username'))
#
#
# ## --- ROUTE X·ª¨ L√ù CH·∫®N ƒêO√ÅN (API) ---
# @app.route('/diagnose', methods=['POST'])
# def diagnose():
#     """API nh·∫≠n ·∫£nh (base64) v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON."""
#     # 1. B·∫£o v·ªá API
#     if 'loggedin' not in session:
#         return jsonify({'error': 'B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ th·ª±c hi·ªán ch·∫©n ƒëo√°n.'}), 401
#
#     # 2. Ki·ªÉm tra m√¥ h√¨nh
#     if model is None:
#         return jsonify({'error': 'M√¥ h√¨nh AI ch∆∞a ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng. Kh√¥ng th·ªÉ ch·∫©n ƒëo√°n.'}), 500
#
#     try:
#         # L·∫•y d·ªØ li·ªáu ·∫£nh Base64 t·ª´ y√™u c·∫ßu POST (d·∫°ng JSON)
#         data = request.get_json()
#         img_data_b64 = data.get('image')
#
#         if not img_data_b64:
#             return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ·∫£nh (base64).'}), 400
#
#         # Th·ª±c hi·ªán d·ª± ƒëo√°n
#         predicted_name, confidence = process_and_predict(img_data_b64)
#
#         if predicted_name in ["L·ªói x·ª≠ l√Ω", "L·ªói t·∫£i m√¥ h√¨nh"]:
#             return jsonify({'error': f'L·ªói h·ªá th·ªëng trong qu√° tr√¨nh d·ª± ƒëo√°n: {predicted_name}'}), 500
#
#         # Tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON
#         return jsonify({
#             'success': True,
#             'prediction': {
#                 'disease': predicted_name,
#                 'confidence': f'{confidence:.2f}%'
#             }
#         })
#
#     except Exception as e:
#         print(f"L·ªñI SERVER trong route /diagnose: {e}")
#         return jsonify({'error': f'L·ªói server kh√¥ng x√°c ƒë·ªãnh: {str(e)}'}), 500
#
#
# # =================================================================
# # 4. CH·∫†Y ·ª®NG D·ª§NG
# # =================================================================
#
# if __name__ == '__main__':
#     app.run(debug=True, host='0.0.0.0', port=5000)




import os
import io
import re
import base64
import numpy as np
from flask import Flask, render_template, request, redirect, url_for, session, jsonify
import mysql.connector

# =================================================================
# THAY ƒê·ªîI L·ªöN: S·ª¨ D·ª§NG C√ÅCH IMPORT LANGCHAIN HI·ªÜN ƒê·∫†I
# =================================================================
from google import genai
# Thay th·∫ø l·ªói c≈© b·∫±ng c√°ch import m·ªõi v√† ch√≠nh x√°c:
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma # D√πng tr·ª±c ti·∫øp langchain-chroma thay v√¨ langchain.vectorstores

# --- C·∫¶N C√ÄI ƒê·∫∂T: ƒë·∫£m b·∫£o ƒë√£ c√†i ƒë·ªß google-genai, langchain-google-genai, langchain-text-splitters, langchain-chroma ---
try:
    import tensorflow as tf
    from tensorflow.keras.preprocessing import image
except ImportError:
    print("!!! L·ªñI: Thi·∫øu th∆∞ vi·ªán AI. Vui l√≤ng c√†i ƒë·∫∑t: pip install tensorflow")
    tf = None

# =================================================================
# 0. C·∫§U H√åNH V√Ä KH·ªûI T·∫†O CHUNG
# =================================================================

os.environ["GOOGLE_API_KEY"] = "AIzaSyDMV72De3esk0KpzpLLEo7PJRWTnwM8vr8"
EMBEDDING_MODEL = "text-embedding-004"
LLM_MODEL = "gemini-2.5-flash"

try:
    gemini_client = genai.Client()
except Exception as e:
    print(f"!!! L·ªñI KH·ªûI T·∫†O GEMINI CLIENT: {e}")

VECTOR_STORE = None
ACTIVE_CHATS = {}

DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': '123456',
    'database': 'benh_ga'
}

MODEL_PATH = r'D:\Hoc Ki Cuoi\Capstone-project-VKU\Web_Final_ok\model\best_model.keras'
CLASS_NAMES = ['Coccidiosis', 'Healthy', 'New Castle Disease', 'Salmonella']
IMG_HEIGHT = 224
IMG_WIDTH = 224

app = Flask(__name__)
app.secret_key = 'mot_chuoi_bi_mat_rat_dai_va_kho'

model = None
if tf is not None:
    try:
        model = tf.keras.models.load_model(MODEL_PATH)
        print(f">>> ‚úÖ M√¥ h√¨nh AI ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng t·ª´: {MODEL_PATH}")
    except Exception as e:
        print(f"!!! L·ªñI: Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh t·ª´ ƒë∆∞·ªùng d·∫´n: {MODEL_PATH}")
        print(f"L·ªói chi ti·∫øt: {e}")
        print("Ch·ª©c nƒÉng ch·∫©n ƒëo√°n AI s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")


# =================================================================
# 1. H√ÄM DATABASE V√Ä RAG
# =================================================================

def get_db_connection():
    """Thi·∫øt l·∫≠p k·∫øt n·ªëi v·ªõi MySQL"""
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        return conn
    except mysql.connector.Error as err:
        print(f"L·ªói k·∫øt n·ªëi database: {err}")
        return None


def load_and_chunk_data():
    """T·∫£i d·ªØ li·ªáu t·ª´ DB, chia chunks v√† t·∫°o Vector Store (Chroma)."""
    global VECTOR_STORE

    if VECTOR_STORE is not None:
        print(">>> ‚úÖ Vector Store ƒë√£ ƒë∆∞·ª£c t·∫£i. B·ªè qua kh·ªüi t·∫°o.")
        return

    conn = get_db_connection()
    if not conn:
        print("!!! L·ªñI: Kh√¥ng th·ªÉ k·∫øt n·ªëi DB ƒë·ªÉ t·∫£i d·ªØ li·ªáu RAG.")
        return

    try:
        cursor = conn.cursor(dictionary=True)
        query = "SELECT ten_benh, dulieubenh FROM benh"
        cursor.execute(query)
        data = cursor.fetchall()
        cursor.close()
        conn.close()

        texts = []
        for row in data:
            # G·ªôp t√™n b·ªánh v√†o n·ªôi dung ƒë·ªÉ l√†m ng·ªØ c·∫£nh
            full_text = f"T√™n b·ªánh: {row['ten_benh']}\n\nChi ti·∫øt: {row['dulieubenh']}"
            texts.append(full_text)

        # Chia Chunks (S·ª≠ d·ª•ng LangChain Text Splitters)
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ".", "!", "?"]
        )

        chunks = text_splitter.create_documents(texts)

        # T·∫°o Embeddings v√† Vector Store (S·ª≠ d·ª•ng langchain_chroma)
        embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
        VECTOR_STORE = Chroma.from_documents(chunks, embeddings)
        print(">>> ‚úÖ C∆° s·ªü d·ªØ li·ªáu Vector RAG (Chroma) ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.")

    except Exception as e:
        print(f"!!! L·ªñI T·∫†O RAG/VECTOR STORE: {e}")
        VECTOR_STORE = None


# --- CH·∫†Y H√ÄM KH·ªûI T·∫†O RAG KHI ·ª®NG D·ª§NG KH·ªûI ƒê·ªòNG ---
@app.before_request
def initialize_rag():
    """Ch·∫°y h√†m kh·ªüi t·∫°o RAG tr∆∞·ªõc khi x·ª≠ l√Ω y√™u c·∫ßu ƒë·∫ßu ti√™n."""
    if VECTOR_STORE is None:
        load_and_chunk_data()


# =================================================================
# 2. H√ÄM X·ª¨ L√ù ·∫¢NH V√Ä D·ª∞ ƒêO√ÅN
# =================================================================

def process_and_predict(base64_img_string):
    """X·ª≠ l√Ω chu·ªói base64 th√†nh ·∫£nh, chu·∫©n h√≥a v√† ƒë∆∞a ra d·ª± ƒëo√°n."""
    if model is None:
        return "L·ªói t·∫£i m√¥ h√¨nh", 0.0

    try:
        img_data = re.sub('^data:image/.+;base64,', '', base64_img_string)
        img_bytes = base64.b64decode(img_data)
        img = image.load_img(io.BytesIO(img_bytes), target_size=(IMG_HEIGHT, IMG_WIDTH))
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = x / 255.0  # CHU·∫®N H√ìA

        predictions = model.predict(x)
        predicted_class_index = np.argmax(predictions[0])
        confidence = np.max(predictions[0]) * 100
        predicted_class_name = CLASS_NAMES[predicted_class_index]

        return predicted_class_name, confidence

    except Exception as e:
        print(f"L·ªñI x·ª≠ l√Ω ·∫£nh/d·ª± ƒëo√°n: {e}")
        return "L·ªói x·ª≠ l√Ω", 0.0


# =================================================================
# 3. ƒê·ªäNH TUY·∫æN (ROUTES) ·ª®NG D·ª§NG
# =================================================================

# --- ROUTE ƒêƒÇNG NH·∫¨P (Login) --- (Gi·ªØ nguy√™n)
@app.route('/', methods=['GET', 'POST'])
@app.route('/login', methods=['GET', 'POST'])
def login_page():
    error_message = None
    if request.method == 'POST':
        taikhoan = request.form.get('taikhoan')
        mk = request.form.get('mk')

        conn = get_db_connection()
        if conn:
            cursor = conn.cursor(dictionary=True)
            query = "SELECT idTaikhoan, taikhoan FROM user WHERE taikhoan = %s AND matkhau = %s"
            cursor.execute(query, (taikhoan, mk))
            user = cursor.fetchone()

            cursor.close()
            conn.close()

            if user:
                session['loggedin'] = True
                session['user_id'] = user.get('idTaikhoan')
                session['username'] = user.get('taikhoan')
                return redirect(url_for('trangchu_page'))
            else:
                error_message = 'T√†i kho·∫£n ho·∫∑c m·∫≠t kh·∫©u kh√¥ng ƒë√∫ng.'
        else:
            error_message = 'L·ªói k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh DB.'

    return render_template('login.html', error=error_message)


# --- ROUTE TRANG CH·ª¶ & PH√ÇN LO·∫†I (Gi·ªØ nguy√™n) ---
@app.route('/trangchu')
def trangchu_page():
    if 'loggedin' not in session:
        return redirect(url_for('login_page'))
    return render_template('trangchu.html', username=session.get('username'))


@app.route('/phan_loai_benh_ga')
def phan_loai_benh_ga_page():
    if 'loggedin' not in session:
        return redirect(url_for('login_page'))
    return render_template('phan_loai_benh_ga.html', username=session.get('username'))


# --- ROUTE X·ª¨ L√ù CH·∫®N ƒêO√ÅN V√Ä KH·ªûI T·∫†O CHAT (T√çCH H·ª¢P RAG) ---
@app.route('/diagnose', methods=['POST'])
def diagnose_and_start_chat():
    """Ch·∫©n ƒëo√°n ·∫£nh, kh·ªüi t·∫°o chat session, v√† tr·∫£ v·ªÅ ph·∫£n h·ªìi RAG ƒë·∫ßu ti√™n."""
    user_id = session.get('user_id')
    if not user_id:
        return jsonify({'error': 'B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ th·ª±c hi·ªán ch·∫©n ƒëo√°n.'}), 401

    if VECTOR_STORE is None:
        return jsonify({'error': 'H·ªá th·ªëng RAG ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.'}), 500

    try:
        # 1. Ch·∫©n ƒëo√°n ·∫£nh
        data = request.get_json()
        img_data_b64 = data.get('image')
        if not img_data_b64:
            return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ·∫£nh (base64).'}), 400

        predicted_name, confidence = process_and_predict(img_data_b64)

        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p Healthy ho·∫∑c L·ªói d·ª± ƒëo√°n
        if predicted_name in ["L·ªói x·ª≠ l√Ω", "L·ªói t·∫£i m√¥ h√¨nh"]:
            return jsonify({
                'success': True,
                'prediction': {'disease': predicted_name, 'confidence': f'{confidence:.2f}%'},
                'initial_chat_response': f"L·ªói h·ªá th·ªëng khi d·ª± ƒëo√°n."
            })

        if predicted_name == "Healthy":
            return jsonify({
                'success': True,
                'prediction': {'disease': predicted_name, 'confidence': f'{confidence:.2f}%'},
                'initial_chat_response': f"K·∫øt qu·∫£ ch·∫©n ƒëo√°n: **{predicted_name}**. G√† c·ªßa b·∫°n kh·ªèe m·∫°nh, h√£y ti·∫øp t·ª•c duy tr√¨ ch·∫ø ƒë·ªô chƒÉm s√≥c t·ªët!"
            })

        # 2. Kh·ªüi t·∫°o Chatbot v√† RAG cho b·ªánh ƒë∆∞·ª£c ch·∫©n ƒëo√°n

        # a. Truy v·∫•n RAG (L·∫•y th√¥ng tin ph√°c ƒë·ªì ban ƒë·∫ßu)
        query_rag = f"Ph√°c ƒë·ªì ƒëi·ªÅu tr·ªã ban ƒë·∫ßu v√† tri·ªáu ch·ª©ng ch√≠nh c·ªßa b·ªánh {predicted_name}"
        rag_docs = VECTOR_STORE.similarity_search(query_rag, k=3)
        rag_context = "\n---\n".join([doc.page_content for doc in rag_docs])

        # b. Thi·∫øt l·∫≠p System Prompt v√† Message
        system_prompt = (
            "B·∫°n l√† chuy√™n gia th√∫ y gia c·∫ßm. H√£y cung c·∫•p t∆∞ v·∫•n chi ti·∫øt D·ª∞A TR√äN NG·ªÆ C·∫¢NH "
            "CHUY√äN M√îN ƒë∆∞·ª£c cung c·∫•p. Tuy·ªát ƒë·ªëi kh√¥ng t·ª± suy di·ªÖn n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu. "
            "S·ª≠ d·ª•ng Markdown ƒë·ªÉ ƒë·ªãnh d·∫°ng c√¢u tr·∫£ l·ªùi d·ªÖ ƒë·ªçc."
        )
        initial_prompt = (
            f"K·∫øt qu·∫£ ch·∫©n ƒëo√°n h√¨nh ·∫£nh l√† **{predicted_name}** v·ªõi ƒë·ªô tin c·∫≠y {confidence:.2f}%. "
            f"D∆∞·ªõi ƒë√¢y l√† c√°c d·ªØ li·ªáu chuy√™n m√¥n v·ªÅ b·ªánh n√†y:\n\n"
            f"--- NGU·ªíN D·ªÆ LI·ªÜU RAG ---\n{rag_context}\n--- END RAG ---\n\n"
            "D·ª±a v√†o th√¥ng tin tr√™n, h√£y ƒë∆∞a ra: 1. T√≥m t·∫Øt nhanh v·ªÅ b·ªánh. 2. Ph√°c ƒë·ªì ƒëi·ªÅu tr·ªã kh·∫©n c·∫•p ban ƒë·∫ßu (thu·ªëc v√† c√°ch ly)."
        )

        # c. Kh·ªüi t·∫°o Chat Session v·ªõi System Prompt
        chat = gemini_client.chats.create(
            model=LLM_MODEL,
            config={'system_instruction': system_prompt}
        )

        # d. G·ª≠i tin nh·∫Øn ƒë·∫ßu ti√™n v√† l∆∞u Session
        initial_response = chat.send_message(initial_prompt)
        ACTIVE_CHATS[user_id] = chat  # L∆∞u l·∫°i phi√™n chat

        # 3. Tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON v√† Ph·∫£n h·ªìi Chatbot
        return jsonify({
            'success': True,
            'prediction': {
                'disease': predicted_name,
                'confidence': f'{confidence:.2f}%'
            },
            'initial_chat_response': initial_response.text
        })

    except Exception as e:
        print(f"L·ªñI KH·ªûI T·∫†O CHAT V√Ä RAG: {e}")
        # X√≥a chat session n·∫øu l·ªói
        if user_id in ACTIVE_CHATS: del ACTIVE_CHATS[user_id]
        return jsonify({'error': f'L·ªói h·ªá th·ªëng khi kh·ªüi t·∫°o t∆∞ v·∫•n: {str(e)}'}), 500


# --- ROUTE X·ª¨ L√ù C√ÇU H·ªéI TI·∫æP THEO ---
@app.route('/chat', methods=['POST'])
def handle_followup_chat():
    """API nh·∫≠n c√¢u h·ªèi ti·∫øp theo, s·ª≠ d·ª•ng RAG v√† phi√™n chat ƒë√£ l∆∞u."""
    user_id = session.get('user_id')
    if not user_id:
        return jsonify({'error': 'B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p.'}), 401

    if user_id not in ACTIVE_CHATS:
        return jsonify({'error': 'Ch∆∞a c√≥ phi√™n chat n√†o ƒë∆∞·ª£c kh·ªüi t·∫°o. Vui l√≤ng ch·∫©n ƒëo√°n tr∆∞·ªõc.'}), 400

    if VECTOR_STORE is None:
        return jsonify({'error': 'H·ªá th·ªëng RAG ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.'}), 500

    try:
        data = request.get_json()
        user_question = data.get('question')

        if not user_question:
            return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi.'}), 400

        # L·∫•y phi√™n chat hi·ªán t·∫°i
        current_chat = ACTIVE_CHATS[user_id]

        # 1. Truy v·∫•n RAG (L·∫•y th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi m·ªõi)
        rag_docs = VECTOR_STORE.similarity_search(user_question, k=3)
        rag_context = "\n---\n".join([doc.page_content for doc in rag_docs])

        # 2. G·ªôp RAG v√†o Prompt
        augmented_prompt = (
            f"D·ª±a tr√™n NG·ªÆ C·∫¢NH B·ªî SUNG d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi: '{user_question}'. "
            f"ƒê·∫£m b·∫£o c√¢u tr·∫£ l·ªùi nh·∫•t qu√°n v·ªõi l·ªãch s·ª≠ tr√≤ chuy·ªán (n·∫øu c√≥).\n\n"
            f"--- NG·ªÆ C·∫¢NH RAG ---\n{rag_context}\n--- END NG·ªÆ C·∫¢NH ---\n"
        )

        # 3. G·ª≠i Prompt TƒÉng c∆∞·ªùng ƒë·∫øn Gemini (gi·ªØ l·∫°i l·ªãch s·ª≠ chat)
        response = current_chat.send_message(augmented_prompt)

        # 4. Tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON
        return jsonify({
            'success': True,
            'response': response.text
        })

    except Exception as e:
        print(f"L·ªñI X·ª¨ L√ù CHAT TI·∫æP THEO: {e}")
        return jsonify({'error': f'L·ªói server kh√¥ng x√°c ƒë·ªãnh: {str(e)}'}), 500


# =================================================================
# 4. CH·∫†Y ·ª®NG D·ª§NG
# =================================================================

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)