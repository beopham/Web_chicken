# import os
# import io
# import re
# import base64
# import numpy as np
# from flask import Flask, render_template, request, redirect, url_for, session, jsonify
# import mysql.connector
# import os
#
#
# EMBEDDING_MODEL = "text-embedding-004"
# # üîë C·∫§U H√åNH API KEY (Thay b·∫±ng key th·∫≠t c·ªßa b·∫°n)
# # LangChain/Google SDK s·∫Ω ƒë·ªçc bi·∫øn n√†y
# os.environ["GOOGLE_API_KEY"] = "AIzaSyDMV72De3esk0KpzpLLEo7PJRWTnwM8vr8"
# VECTOR_STORE = None # Bi·∫øn to√†n c·ª•c ch·ª©a c∆° s·ªü d·ªØ li·ªáu vector
# # --- C·∫¶N C√ÄI ƒê·∫∂T: pip install flask tensorflow pillow numpy mysql-connector-python ---
# try:
#     import tensorflow as tf
#     from tensorflow.keras.preprocessing import image
# except ImportError:
#     print("!!! L·ªñI: Thi·∫øu th∆∞ vi·ªán AI. Vui l√≤ng c√†i ƒë·∫∑t: pip install tensorflow")
#
# # =================================================================
# # 1. C·∫§U H√åNH DATABASE
# # =================================================================
# DB_CONFIG = {
#     'host': 'localhost',
#     'user': 'root',
#     'password': '123456',
#     'database': 'benh_ga'
# }
#
#
# # --- H√ÄM K·∫æT N·ªêI DATABASE ---
# def get_db_connection():
#     """Thi·∫øt l·∫≠p k·∫øt n·ªëi v·ªõi MySQL"""
#     try:
#         conn = mysql.connector.connect(**DB_CONFIG)
#         return conn
#     except mysql.connector.Error as err:
#         print(f"L·ªói k·∫øt n·ªëi database: {err}")
#         return None
#
#
# # =================================================================
# # 2. C·∫§U H√åNH V√Ä T·∫¢I M√î H√åNH AI
# # =================================================================
#
# # ƒê∆Ø·ªúNG D·∫™N M√î H√åNH C·ª¶A B·∫†N
# MODEL_PATH = r'D:\Hoc Ki Cuoi\Capstone-project-VKU\Web_Final_ok\model\best_model.keras'
#
# # T√™n 4 l·ªõp b·ªánh (PH·∫¢I ƒê√öNG TH·ª® T·ª∞ ABC)
# CLASS_NAMES = ['Coccidiosis', 'Healthy', 'New Castle Disease', 'Salmonella']
# # K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o
# IMG_HEIGHT = 224
# IMG_WIDTH = 224
#
# app = Flask(__name__)
# # KHAI B√ÅO KEY B√ç M·∫¨T CHO SESSION (B·∫Øt bu·ªôc)
# app.secret_key = 'mot_chuoi_bi_mat_rat_dai_va_kho'
#
# # T·∫¢I M√î H√åNH (Ch·ªâ 1 l·∫ßn)
# model = None
# try:
#     if tf is not None:
#         model = tf.keras.models.load_model(MODEL_PATH)
#         print(f">>> ‚úÖ M√¥ h√¨nh AI ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng t·ª´: {MODEL_PATH}")
# except Exception as e:
#     print(f"!!! L·ªñI: Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh t·ª´ ƒë∆∞·ªùng d·∫´n: {MODEL_PATH}")
#     print(f"L·ªói chi ti·∫øt: {e}")
#     print("Ch·ª©c nƒÉng ch·∫©n ƒëo√°n AI s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")
#
#
# # -------------------------------------------------------------------------
# ## --- H√ÄM TI·ªÄN X·ª¨ L√ù ·∫¢NH (D√ôNG CHO CH·∫®N ƒêO√ÅN AI) ---
# # -------------------------------------------------------------------------
# def process_and_predict(base64_img_string):
#     """X·ª≠ l√Ω chu·ªói base64 th√†nh ·∫£nh, chu·∫©n h√≥a v√† ƒë∆∞a ra d·ª± ƒëo√°n."""
#     if model is None:
#         return "L·ªói t·∫£i m√¥ h√¨nh", 0.0
#
#     try:
#         # X√≥a ph·∫ßn header base64 (v√≠ d·ª•: data:image/jpeg;base64,)
#         img_data = re.sub('^data:image/.+;base64,', '', base64_img_string)
#         img_bytes = base64.b64decode(img_data)
#
#         # Chuy·ªÉn bytes th√†nh ·∫£nh v√† resize
#         img = image.load_img(io.BytesIO(img_bytes), target_size=(IMG_HEIGHT, IMG_WIDTH))
#
#         # Chu·∫©n b·ªã cho m√¥ h√¨nh
#         x = image.img_to_array(img)
#         x = np.expand_dims(x, axis=0)
#
#         # CHU·∫®N H√ìA (Ph·∫£i kh·ªõp v·ªõi qu√° tr√¨nh hu·∫•n luy·ªán)
#         x = x / 255.0
#
#         # D·ª± ƒëo√°n
#         predictions = model.predict(x)
#
#         # L·∫•y k·∫øt qu·∫£
#         predicted_class_index = np.argmax(predictions[0])
#         confidence = np.max(predictions[0]) * 100
#         predicted_class_name = CLASS_NAMES[predicted_class_index]
#
#         return predicted_class_name, confidence
#
#     except Exception as e:
#         print(f"L·ªñI x·ª≠ l√Ω ·∫£nh/d·ª± ƒëo√°n: {e}")
#         return "L·ªói x·ª≠ l√Ω", 0.0
#
#
# # =================================================================
# # 3. ƒê·ªäNH TUY·∫æN (ROUTES) ·ª®NG D·ª§NG
# # =================================================================
#
# ## --- ROUTE ƒêƒÇNG NH·∫¨P (Login) ---
# @app.route('/', methods=['GET', 'POST'])
# @app.route('/login', methods=['GET', 'POST'])
# def login_page():
#     error_message = None
#     if request.method == 'POST':
#         taikhoan = request.form.get('taikhoan')
#         mk = request.form.get('mk')
#
#         conn = get_db_connection()
#         if conn:
#             cursor = conn.cursor(dictionary=True)
#             query = "SELECT * FROM user WHERE taikhoan = %s AND matkhau = %s"
#             cursor.execute(query, (taikhoan, mk))
#             user = cursor.fetchone()
#
#             cursor.close()
#             conn.close()
#
#             if user:
#                 session['loggedin'] = True
#                 session['username'] = user.get('taikhoan')
#                 return redirect(url_for('trangchu_page'))
#             else:
#                 error_message = 'T√†i kho·∫£n ho·∫∑c m·∫≠t kh·∫©u kh√¥ng ƒë√∫ng.'
#         else:
#             error_message = 'L·ªói k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh DB.'
#
#     # Hi·ªÉn th·ªã trang login
#     return render_template('login.html', error=error_message)
#
#
# ## --- ROUTE TRANG CH·ª¶ (Sau khi ƒëƒÉng nh·∫≠p) ---
# @app.route('/trangchu')
# def trangchu_page():
#     # B·∫£o v·ªá trang
#     if 'loggedin' not in session:
#         return redirect(url_for('login_page'))
#
#     return render_template('trangchu.html', username=session.get('username'))
#
#
# ## --- ROUTE PH√ÇN LO·∫†I B·ªÜNH G√Ä (Form t·∫£i ·∫£nh) ---
# @app.route('/phan_loai_benh_ga')
# def phan_loai_benh_ga_page():
#     # B·∫£o v·ªá trang
#     if 'loggedin' not in session:
#         return redirect(url_for('login_page'))
#
#     # Trang n√†y ch·ª©a form HTML/JS ƒë·ªÉ g·ª≠i ·∫£nh l√™n API /diagnose
#     return render_template('phan_loai_benh_ga.html', username=session.get('username'))
#
#
# ## --- ROUTE X·ª¨ L√ù CH·∫®N ƒêO√ÅN (API) ---
# @app.route('/diagnose', methods=['POST'])
# def diagnose():
#     """API nh·∫≠n ·∫£nh (base64) v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON."""
#     # 1. B·∫£o v·ªá API
#     if 'loggedin' not in session:
#         return jsonify({'error': 'B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ th·ª±c hi·ªán ch·∫©n ƒëo√°n.'}), 401
#
#     # 2. Ki·ªÉm tra m√¥ h√¨nh
#     if model is None:
#         return jsonify({'error': 'M√¥ h√¨nh AI ch∆∞a ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng. Kh√¥ng th·ªÉ ch·∫©n ƒëo√°n.'}), 500
#
#     try:
#         # L·∫•y d·ªØ li·ªáu ·∫£nh Base64 t·ª´ y√™u c·∫ßu POST (d·∫°ng JSON)
#         data = request.get_json()
#         img_data_b64 = data.get('image')
#
#         if not img_data_b64:
#             return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ·∫£nh (base64).'}), 400
#
#         # Th·ª±c hi·ªán d·ª± ƒëo√°n
#         predicted_name, confidence = process_and_predict(img_data_b64)
#
#         if predicted_name in ["L·ªói x·ª≠ l√Ω", "L·ªói t·∫£i m√¥ h√¨nh"]:
#             return jsonify({'error': f'L·ªói h·ªá th·ªëng trong qu√° tr√¨nh d·ª± ƒëo√°n: {predicted_name}'}), 500
#
#         # Tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON
#         return jsonify({
#             'success': True,
#             'prediction': {
#                 'disease': predicted_name,
#                 'confidence': f'{confidence:.2f}%'
#             }
#         })
#
#     except Exception as e:
#         print(f"L·ªñI SERVER trong route /diagnose: {e}")
#         return jsonify({'error': f'L·ªói server kh√¥ng x√°c ƒë·ªãnh: {str(e)}'}), 500
#
#
# # =================================================================
# # 4. CH·∫†Y ·ª®NG D·ª§NG
# # =================================================================
#
# if __name__ == '__main__':
#     app.run(debug=True, host='0.0.0.0', port=5000)


#
# import os
# import io
# import re
# import base64
# import numpy as np
# from flask import Flask, render_template, request, redirect, url_for, session, jsonify
# import mysql.connector
#
# # =================================================================
# # THAY ƒê·ªîI L·ªöN: S·ª¨ D·ª§NG C√ÅCH IMPORT LANGCHAIN HI·ªÜN ƒê·∫†I
# # =================================================================
# from google import genai
# # Thay th·∫ø l·ªói c≈© b·∫±ng c√°ch import m·ªõi v√† ch√≠nh x√°c:
# from langchain_text_splitters import RecursiveCharacterTextSplitter
# from langchain_google_genai import GoogleGenerativeAIEmbeddings
# from langchain_chroma import Chroma # D√πng tr·ª±c ti·∫øp langchain-chroma thay v√¨ langchain.vectorstores
#
# # --- C·∫¶N C√ÄI ƒê·∫∂T: ƒë·∫£m b·∫£o ƒë√£ c√†i ƒë·ªß google-genai, langchain-google-genai, langchain-text-splitters, langchain-chroma ---
# try:
#     import tensorflow as tf
#     from tensorflow.keras.preprocessing import image
# except ImportError:
#     print("!!! L·ªñI: Thi·∫øu th∆∞ vi·ªán AI. Vui l√≤ng c√†i ƒë·∫∑t: pip install tensorflow")
#     tf = None
#
# # =================================================================
# # 0. C·∫§U H√åNH V√Ä KH·ªûI T·∫†O CHUNG
# # =================================================================
#
# os.environ["GOOGLE_API_KEY"] = "AIzaSyCifSb7b1ldIDPiSn7Gz2ZCmTm6HtaLbr0"
# EMBEDDING_MODEL = "text-embedding-004"
# LLM_MODEL = "gemini-2.5-flash"
#
# try:
#     gemini_client = genai.Client()
# except Exception as e:
#     print(f"!!! L·ªñI KH·ªûI T·∫†O GEMINI CLIENT: {e}")
#
# VECTOR_STORE = None
# ACTIVE_CHATS = {}
#
# DB_CONFIG = {
#     'host': 'localhost',
#     'user': 'root',
#     'password': '123456',
#     'database': 'benh_ga'
# }
#
# MODEL_PATH = r'D:\Hoc Ki Cuoi\Web_Chicken\web\model\best_model.keras'
# CLASS_NAMES = ['Coccidiosis', 'Healthy', 'New Castle Disease', 'Salmonella']
# IMG_HEIGHT = 224
# IMG_WIDTH = 224
#
# app = Flask(__name__)
# app.secret_key = 'mot_chuoi_bi_mat_rat_dai_va_kho'
#
# model = None
# if tf is not None:
#     try:
#         model = tf.keras.models.load_model(MODEL_PATH)
#         print(f">>> ‚úÖ M√¥ h√¨nh AI ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng t·ª´: {MODEL_PATH}")
#     except Exception as e:
#         print(f"!!! L·ªñI: Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh t·ª´ ƒë∆∞·ªùng d·∫´n: {MODEL_PATH}")
#         print(f"L·ªói chi ti·∫øt: {e}")
#         print("Ch·ª©c nƒÉng ch·∫©n ƒëo√°n AI s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")
#
#
# # =================================================================
# # 1. H√ÄM DATABASE V√Ä RAG
# # =================================================================
#
# def get_db_connection():
#     """Thi·∫øt l·∫≠p k·∫øt n·ªëi v·ªõi MySQL"""
#     try:
#         conn = mysql.connector.connect(**DB_CONFIG)
#         return conn
#     except mysql.connector.Error as err:
#         print(f"L·ªói k·∫øt n·ªëi database: {err}")
#         return None
#
#
# def load_and_chunk_data():
#     """T·∫£i d·ªØ li·ªáu t·ª´ DB, chia chunks v√† t·∫°o Vector Store (Chroma)."""
#     global VECTOR_STORE
#
#     if VECTOR_STORE is not None:
#         print(">>> ‚úÖ Vector Store ƒë√£ ƒë∆∞·ª£c t·∫£i. B·ªè qua kh·ªüi t·∫°o.")
#         return
#
#     conn = get_db_connection()
#     if not conn:
#         print("!!! L·ªñI: Kh√¥ng th·ªÉ k·∫øt n·ªëi DB ƒë·ªÉ t·∫£i d·ªØ li·ªáu RAG.")
#         return
#
#     try:
#         cursor = conn.cursor(dictionary=True)
#         query = "SELECT ten_benh, dulieubenh FROM benh"
#         cursor.execute(query)
#         data = cursor.fetchall()
#         cursor.close()
#         conn.close()
#
#         texts = []
#         for row in data:
#             # G·ªôp t√™n b·ªánh v√†o n·ªôi dung ƒë·ªÉ l√†m ng·ªØ c·∫£nh
#             full_text = f"T√™n b·ªánh: {row['ten_benh']}\n\nChi ti·∫øt: {row['dulieubenh']}"
#             texts.append(full_text)
#
#         # Chia Chunks (S·ª≠ d·ª•ng LangChain Text Splitters)
#         text_splitter = RecursiveCharacterTextSplitter(
#             chunk_size=2000,
#             chunk_overlap=200,
#             separators=["\n\n", "\n", ".", "!", "?"]
#         )
#
#         chunks = text_splitter.create_documents(texts)
#
#         # T·∫°o Embeddings v√† Vector Store (S·ª≠ d·ª•ng langchain_chroma)
#         embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
#         VECTOR_STORE = Chroma.from_documents(chunks, embeddings)
#         print(">>> ‚úÖ C∆° s·ªü d·ªØ li·ªáu Vector RAG (Chroma) ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.")
#
#     except Exception as e:
#         print(f"!!! L·ªñI T·∫†O RAG/VECTOR STORE: {e}")
#         VECTOR_STORE = None
#
#
# # --- CH·∫†Y H√ÄM KH·ªûI T·∫†O RAG KHI ·ª®NG D·ª§NG KH·ªûI ƒê·ªòNG ---
# @app.before_request
# def initialize_rag():
#     """Ch·∫°y h√†m kh·ªüi t·∫°o RAG tr∆∞·ªõc khi x·ª≠ l√Ω y√™u c·∫ßu ƒë·∫ßu ti√™n."""
#     if VECTOR_STORE is None:
#         load_and_chunk_data()
#
#
# # =================================================================
# # 2. H√ÄM X·ª¨ L√ù ·∫¢NH V√Ä D·ª∞ ƒêO√ÅN
# # =================================================================
#
# def process_and_predict(base64_img_string):
#     """X·ª≠ l√Ω chu·ªói base64 th√†nh ·∫£nh, chu·∫©n h√≥a v√† ƒë∆∞a ra d·ª± ƒëo√°n."""
#     if model is None:
#         return "L·ªói t·∫£i m√¥ h√¨nh", 0.0
#
#     try:
#         img_data = re.sub('^data:image/.+;base64,', '', base64_img_string)
#         img_bytes = base64.b64decode(img_data)
#         img = image.load_img(io.BytesIO(img_bytes), target_size=(IMG_HEIGHT, IMG_WIDTH))
#         x = image.img_to_array(img)
#         x = np.expand_dims(x, axis=0)
#         x = x / 255.0  # CHU·∫®N H√ìA
#
#         predictions = model.predict(x)
#         predicted_class_index = np.argmax(predictions[0])
#         confidence = np.max(predictions[0]) * 100
#         predicted_class_name = CLASS_NAMES[predicted_class_index]
#
#         return predicted_class_name, confidence
#
#     except Exception as e:
#         print(f"L·ªñI x·ª≠ l√Ω ·∫£nh/d·ª± ƒëo√°n: {e}")
#         return "L·ªói x·ª≠ l√Ω", 0.0
#
#
# # =================================================================
# # 3. ƒê·ªäNH TUY·∫æN (ROUTES) ·ª®NG D·ª§NG
# # =================================================================
#
# # --- ROUTE ƒêƒÇNG NH·∫¨P (Login) --- (Gi·ªØ nguy√™n)
# @app.route('/', methods=['GET', 'POST'])
# @app.route('/login', methods=['GET', 'POST'])
# def login_page():
#     error_message = None
#     if request.method == 'POST':
#         taikhoan = request.form.get('taikhoan')
#         mk = request.form.get('mk')
#
#         conn = get_db_connection()
#         if conn:
#             cursor = conn.cursor(dictionary=True)
#             query = "SELECT idTaikhoan, taikhoan FROM user WHERE taikhoan = %s AND matkhau = %s"
#             cursor.execute(query, (taikhoan, mk))
#             user = cursor.fetchone()
#
#             cursor.close()
#             conn.close()
#
#             if user:
#                 session['loggedin'] = True
#                 session['user_id'] = user.get('idTaikhoan')
#                 session['username'] = user.get('taikhoan')
#                 return redirect(url_for('trangchu_page'))
#             else:
#                 error_message = 'T√†i kho·∫£n ho·∫∑c m·∫≠t kh·∫©u kh√¥ng ƒë√∫ng.'
#         else:
#             error_message = 'L·ªói k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh DB.'
#
#     return render_template('login.html', error=error_message)
#
#
# # --- ROUTE TRANG CH·ª¶ & PH√ÇN LO·∫†I (Gi·ªØ nguy√™n) ---
# @app.route('/trangchu')
# def trangchu_page():
#     if 'loggedin' not in session:
#         return redirect(url_for('login_page'))
#     return render_template('trangchu.html', username=session.get('username'))
#
#
# @app.route('/phan_loai_benh_ga')
# def phan_loai_benh_ga_page():
#     if 'loggedin' not in session:
#         return redirect(url_for('login_page'))
#     return render_template('phan_loai_benh_ga.html', username=session.get('username'))
#
#
# # --- ROUTE X·ª¨ L√ù CH·∫®N ƒêO√ÅN V√Ä KH·ªûI T·∫†O CHAT (T√çCH H·ª¢P RAG) ---
# @app.route('/diagnose', methods=['POST'])
# def diagnose_and_start_chat():
#     """Ch·∫©n ƒëo√°n ·∫£nh, kh·ªüi t·∫°o chat session, v√† tr·∫£ v·ªÅ ph·∫£n h·ªìi RAG ƒë·∫ßu ti√™n."""
#     user_id = session.get('user_id')
#     if not user_id:
#         return jsonify({'error': 'B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ th·ª±c hi·ªán ch·∫©n ƒëo√°n.'}), 401
#
#     if VECTOR_STORE is None:
#         return jsonify({'error': 'H·ªá th·ªëng RAG ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.'}), 500
#
#     try:
#         # 1. Ch·∫©n ƒëo√°n ·∫£nh
#         data = request.get_json()
#         img_data_b64 = data.get('image')
#         if not img_data_b64:
#             return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ·∫£nh (base64).'}), 400
#
#         predicted_name, confidence = process_and_predict(img_data_b64)
#
#         # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p Healthy ho·∫∑c L·ªói d·ª± ƒëo√°n
#         if predicted_name in ["L·ªói x·ª≠ l√Ω", "L·ªói t·∫£i m√¥ h√¨nh"]:
#             return jsonify({
#                 'success': True,
#                 'prediction': {'disease': predicted_name, 'confidence': f'{confidence:.2f}%'},
#                 'initial_chat_response': f"L·ªói h·ªá th·ªëng khi d·ª± ƒëo√°n."
#             })
#
#         if predicted_name == "Healthy":
#             return jsonify({
#                 'success': True,
#                 'prediction': {'disease': predicted_name, 'confidence': f'{confidence:.2f}%'},
#                 'initial_chat_response': f"K·∫øt qu·∫£ ch·∫©n ƒëo√°n: **{predicted_name}**. G√† c·ªßa b·∫°n kh·ªèe m·∫°nh, h√£y ti·∫øp t·ª•c duy tr√¨ ch·∫ø ƒë·ªô chƒÉm s√≥c t·ªët!"
#             })
#
#         # 2. Kh·ªüi t·∫°o Chatbot v√† RAG cho b·ªánh ƒë∆∞·ª£c ch·∫©n ƒëo√°n
#
#         # a. Truy v·∫•n RAG (L·∫•y th√¥ng tin ph√°c ƒë·ªì ban ƒë·∫ßu)
#         query_rag = f"Ph√°c ƒë·ªì ƒëi·ªÅu tr·ªã ban ƒë·∫ßu v√† tri·ªáu ch·ª©ng ch√≠nh c·ªßa b·ªánh {predicted_name}"
#         rag_docs = VECTOR_STORE.similarity_search(query_rag, k=3)
#         rag_context = "\n---\n".join([doc.page_content for doc in rag_docs])
#
#         # b. Thi·∫øt l·∫≠p System Prompt v√† Message
#         system_prompt = (
#             "B·∫°n l√† chuy√™n gia th√∫ y gia c·∫ßm. H√£y cung c·∫•p t∆∞ v·∫•n chi ti·∫øt D·ª∞A TR√äN NG·ªÆ C·∫¢NH "
#             "CHUY√äN M√îN ƒë∆∞·ª£c cung c·∫•p. Tuy·ªát ƒë·ªëi kh√¥ng t·ª± suy di·ªÖn n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu. "
#             "S·ª≠ d·ª•ng Markdown ƒë·ªÉ ƒë·ªãnh d·∫°ng c√¢u tr·∫£ l·ªùi d·ªÖ ƒë·ªçc."
#         )
#         initial_prompt = (
#             f"K·∫øt qu·∫£ ch·∫©n ƒëo√°n h√¨nh ·∫£nh l√† **{predicted_name}** v·ªõi ƒë·ªô tin c·∫≠y {confidence:.2f}%. "
#             f"D∆∞·ªõi ƒë√¢y l√† c√°c d·ªØ li·ªáu chuy√™n m√¥n v·ªÅ b·ªánh n√†y:\n\n"
#             f"--- NGU·ªíN D·ªÆ LI·ªÜU RAG ---\n{rag_context}\n--- END RAG ---\n\n"
#             "D·ª±a v√†o th√¥ng tin tr√™n, h√£y ƒë∆∞a ra: 1. T√≥m t·∫Øt nhanh v·ªÅ b·ªánh. 2. Ph√°c ƒë·ªì ƒëi·ªÅu tr·ªã kh·∫©n c·∫•p ban ƒë·∫ßu (thu·ªëc v√† c√°ch ly)."
#         )
#
#         # c. Kh·ªüi t·∫°o Chat Session v·ªõi System Prompt
#         chat = gemini_client.chats.create(
#             model=LLM_MODEL,
#             config={'system_instruction': system_prompt}
#         )
#
#         # d. G·ª≠i tin nh·∫Øn ƒë·∫ßu ti√™n v√† l∆∞u Session
#         initial_response = chat.send_message(initial_prompt)
#         ACTIVE_CHATS[user_id] = chat  # L∆∞u l·∫°i phi√™n chat
#
#         # 3. Tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON v√† Ph·∫£n h·ªìi Chatbot
#         return jsonify({
#             'success': True,
#             'prediction': {
#                 'disease': predicted_name,
#                 'confidence': f'{confidence:.2f}%'
#             },
#             'initial_chat_response': initial_response.text
#         })
#
#     except Exception as e:
#         print(f"L·ªñI KH·ªûI T·∫†O CHAT V√Ä RAG: {e}")
#         # X√≥a chat session n·∫øu l·ªói
#         if user_id in ACTIVE_CHATS: del ACTIVE_CHATS[user_id]
#         return jsonify({'error': f'L·ªói h·ªá th·ªëng khi kh·ªüi t·∫°o t∆∞ v·∫•n: {str(e)}'}), 500
#
#
# # --- ROUTE X·ª¨ L√ù C√ÇU H·ªéI TI·∫æP THEO ---
# @app.route('/chat', methods=['POST'])
# def handle_followup_chat():
#     """API nh·∫≠n c√¢u h·ªèi ti·∫øp theo, s·ª≠ d·ª•ng RAG v√† phi√™n chat ƒë√£ l∆∞u."""
#     user_id = session.get('user_id')
#     if not user_id:
#         return jsonify({'error': 'B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p.'}), 401
#
#     if user_id not in ACTIVE_CHATS:
#         return jsonify({'error': 'Ch∆∞a c√≥ phi√™n chat n√†o ƒë∆∞·ª£c kh·ªüi t·∫°o. Vui l√≤ng ch·∫©n ƒëo√°n tr∆∞·ªõc.'}), 400
#
#     if VECTOR_STORE is None:
#         return jsonify({'error': 'H·ªá th·ªëng RAG ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.'}), 500
#
#     try:
#         data = request.get_json()
#         user_question = data.get('question')
#
#         if not user_question:
#             return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi.'}), 400
#
#         # L·∫•y phi√™n chat hi·ªán t·∫°i
#         current_chat = ACTIVE_CHATS[user_id]
#
#         # 1. Truy v·∫•n RAG (L·∫•y th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi m·ªõi)
#         rag_docs = VECTOR_STORE.similarity_search(user_question, k=3)
#         rag_context = "\n---\n".join([doc.page_content for doc in rag_docs])
#
#         # 2. G·ªôp RAG v√†o Prompt
#         augmented_prompt = (
#             f"D·ª±a tr√™n NG·ªÆ C·∫¢NH B·ªî SUNG d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi: '{user_question}'. "
#             f"ƒê·∫£m b·∫£o c√¢u tr·∫£ l·ªùi nh·∫•t qu√°n v·ªõi l·ªãch s·ª≠ tr√≤ chuy·ªán (n·∫øu c√≥).\n\n"
#             f"--- NG·ªÆ C·∫¢NH RAG ---\n{rag_context}\n--- END NG·ªÆ C·∫¢NH ---\n"
#         )
#
#         # 3. G·ª≠i Prompt TƒÉng c∆∞·ªùng ƒë·∫øn Gemini (gi·ªØ l·∫°i l·ªãch s·ª≠ chat)
#         response = current_chat.send_message(augmented_prompt)
#
#         # 4. Tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON
#         return jsonify({
#             'success': True,
#             'response': response.text
#         })
#
#     except Exception as e:
#         print(f"L·ªñI X·ª¨ L√ù CHAT TI·∫æP THEO: {e}")
#         return jsonify({'error': f'L·ªói server kh√¥ng x√°c ƒë·ªãnh: {str(e)}'}), 500
#
#
# # =================================================================
# # 4. CH·∫†Y ·ª®NG D·ª§NG
# # =================================================================
#
# if __name__ == '__main__':
#     app.run(debug=True, host='0.0.0.0', port=5000)
#
#
#
#
# import os
# import io
# import re
# import base64
# import numpy as np
# from flask import Flask, render_template, request, redirect, url_for, session, jsonify
# import mysql.connector
#
# # =================================================================
# # THAY ƒê·ªîI L·ªöN: S·ª¨ D·ª§NG C√ÅCH IMPORT LANGCHAIN HI·ªÜN ƒê·∫†I
# # =================================================================
# from google import genai
# # Thay th·∫ø l·ªói c≈© b·∫±ng c√°ch import m·ªõi v√† ch√≠nh x√°c:
# from langchain_text_splitters import RecursiveCharacterTextSplitter
# from langchain_google_genai import GoogleGenerativeAIEmbeddings
# from langchain_chroma import Chroma # D√πng tr·ª±c ti·∫øp langchain-chroma thay v√¨ langchain.vectorstores
#
# # --- C·∫¶N C√ÄI ƒê·∫∂T: ƒë·∫£m b·∫£o ƒë√£ c√†i ƒë·ªß google-genai, langchain-google-genai, langchain-text-splitters, langchain-chroma ---
# try:
#     import tensorflow as tf
#     from tensorflow.keras.preprocessing import image
# except ImportError:
#     print("!!! L·ªñI: Thi·∫øu th∆∞ vi·ªán AI. Vui l√≤ng c√†i ƒë·∫∑t: pip install tensorflow")
#     tf = None
#
# # =================================================================
# # 0. C·∫§U H√åNH V√Ä KH·ªûI T·∫†O CHUNG
# # =================================================================
#
# os.environ["GOOGLE_API_KEY"] = "AIzaSyCifSb7b1ldIDPiSn7Gz2ZCmTm6HtaLbr0"
# EMBEDDING_MODEL = "text-embedding-004"
# LLM_MODEL = "gemini-flash-latest"
# try:
#     gemini_client = genai.Client()
# except Exception as e:
#     print(f"!!! L·ªñI KH·ªûI T·∫†O GEMINI CLIENT: {e}")
#
# VECTOR_STORE = None
# ACTIVE_CHATS = {}
#
# DB_CONFIG = {
#     'host': 'localhost',
#     'user': 'root',
#     'password': '123456',
#     'database': 'benh_ga'
# }
#
# MODEL_PATH = r'D:\Hoc Ki Cuoi\Web_Chicken\web\model\best_model.keras'
# CLASS_NAMES = ['Coccidiosis', 'Healthy', 'New Castle Disease', 'Salmonella']
# IMG_HEIGHT = 224
# IMG_WIDTH = 224
#
# app = Flask(__name__)
# app.secret_key = 'mot_chuoi_bi_mat_rat_dai_va_kho'
#
# model = None
# if tf is not None:
#     try:
#         model = tf.keras.models.load_model(MODEL_PATH)
#         print(f">>> ‚úÖ M√¥ h√¨nh AI ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng t·ª´: {MODEL_PATH}")
#     except Exception as e:
#         print(f"!!! L·ªñI: Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh t·ª´ ƒë∆∞·ªùng d·∫´n: {MODEL_PATH}")
#         print(f"L·ªói chi ti·∫øt: {e}")
#         print("Ch·ª©c nƒÉng ch·∫©n ƒëo√°n AI s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")
#
#
# # =================================================================
# # 1. H√ÄM DATABASE V√Ä RAG
# # =================================================================
#
# def get_db_connection():
#     """Thi·∫øt l·∫≠p k·∫øt n·ªëi v·ªõi MySQL"""
#     try:
#         conn = mysql.connector.connect(**DB_CONFIG)
#         return conn
#     except mysql.connector.Error as err:
#         print(f"L·ªói k·∫øt n·ªëi database: {err}")
#         return None
#
#
# def load_and_chunk_data():
#     """T·∫£i d·ªØ li·ªáu t·ª´ DB, chia chunks v√† t·∫°o Vector Store (Chroma)."""
#     global VECTOR_STORE
#
#     if VECTOR_STORE is not None:
#         print(">>> ‚úÖ Vector Store ƒë√£ ƒë∆∞·ª£c t·∫£i. B·ªè qua kh·ªüi t·∫°o.")
#         return
#
#     conn = get_db_connection()
#     if not conn:
#         print("!!! L·ªñI: Kh√¥ng th·ªÉ k·∫øt n·ªëi DB ƒë·ªÉ t·∫£i d·ªØ li·ªáu RAG.")
#         return
#
#     try:
#         cursor = conn.cursor(dictionary=True)
#         query = "SELECT ten_benh, dulieubenh FROM benh"
#         cursor.execute(query)
#         data = cursor.fetchall()
#         cursor.close()
#         conn.close()
#
#         texts = []
#         for row in data:
#             # G·ªôp t√™n b·ªánh v√†o n·ªôi dung ƒë·ªÉ l√†m ng·ªØ c·∫£nh
#             full_text = f"T√™n b·ªánh: {row['ten_benh']}\n\nChi ti·∫øt: {row['dulieubenh']}"
#             texts.append(full_text)
#
#         # Chia Chunks (S·ª≠ d·ª•ng LangChain Text Splitters)
#         text_splitter = RecursiveCharacterTextSplitter(
#             chunk_size=800,
#             chunk_overlap=80,
#             separators=["\n\n", "\n", ".", "!", "?"]
#         )
#
#         chunks = text_splitter.create_documents(texts)
#
#         # T·∫°o Embeddings v√† Vector Store (S·ª≠ d·ª•ng langchain_chroma)
#         embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
#         VECTOR_STORE = Chroma.from_documents(chunks, embeddings)
#         print(">>> ‚úÖ C∆° s·ªü d·ªØ li·ªáu Vector RAG (Chroma) ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.")
#
#     except Exception as e:
#         print(f"!!! L·ªñI T·∫†O RAG/VECTOR STORE: {e}")
#         VECTOR_STORE = None
#
#
# # --- CH·∫†Y H√ÄM KH·ªûI T·∫†O RAG KHI ·ª®NG D·ª§NG KH·ªûI ƒê·ªòNG ---
# @app.before_request
# def initialize_rag():
#     """Ch·∫°y h√†m kh·ªüi t·∫°o RAG tr∆∞·ªõc khi x·ª≠ l√Ω y√™u c·∫ßu ƒë·∫ßu ti√™n."""
#     if VECTOR_STORE is None:
#         load_and_chunk_data()
#
#
# # =================================================================
# # 2. H√ÄM X·ª¨ L√ù ·∫¢NH V√Ä D·ª∞ ƒêO√ÅN
# # =================================================================
#
# def process_and_predict(base64_img_string):
#     """X·ª≠ l√Ω chu·ªói base64 th√†nh ·∫£nh, chu·∫©n h√≥a v√† ƒë∆∞a ra d·ª± ƒëo√°n."""
#     if model is None:
#         return "L·ªói t·∫£i m√¥ h√¨nh", 0.0
#
#     try:
#         img_data = re.sub('^data:image/.+;base64,', '', base64_img_string)
#         img_bytes = base64.b64decode(img_data)
#         img = image.load_img(io.BytesIO(img_bytes), target_size=(IMG_HEIGHT, IMG_WIDTH))
#         x = image.img_to_array(img)
#         x = np.expand_dims(x, axis=0)
#         x = x / 255.0  # CHU·∫®N H√ìA
#
#         predictions = model.predict(x)
#         predicted_class_index = np.argmax(predictions[0])
#         confidence = np.max(predictions[0]) * 100
#         predicted_class_name = CLASS_NAMES[predicted_class_index]
#
#         return predicted_class_name, confidence
#
#     except Exception as e:
#         print(f"L·ªñI x·ª≠ l√Ω ·∫£nh/d·ª± ƒëo√°n: {e}")
#         return "L·ªói x·ª≠ l√Ω", 0.0
#
#
# # =================================================================
# # 3. ƒê·ªäNH TUY·∫æN (ROUTES) ·ª®NG D·ª§NG
# # =================================================================
#
# # --- ROUTE ƒêƒÇNG NH·∫¨P (Login) --- (Gi·ªØ nguy√™n)
# @app.route('/', methods=['GET', 'POST'])
# @app.route('/login', methods=['GET', 'POST'])
# def login_page():
#     error_message = None
#     if request.method == 'POST':
#         taikhoan = request.form.get('taikhoan')
#         mk = request.form.get('mk')
#
#         conn = get_db_connection()
#         if conn:
#             cursor = conn.cursor(dictionary=True)
#             query = "SELECT idTaikhoan, taikhoan FROM user WHERE taikhoan = %s AND matkhau = %s"
#             cursor.execute(query, (taikhoan, mk))
#             user = cursor.fetchone()
#
#             cursor.close()
#             conn.close()
#
#             if user:
#                 session['loggedin'] = True
#                 session['user_id'] = user.get('idTaikhoan')
#                 session['username'] = user.get('taikhoan')
#                 return redirect(url_for('trangchu_page'))
#             else:
#                 error_message = 'T√†i kho·∫£n ho·∫∑c m·∫≠t kh·∫©u kh√¥ng ƒë√∫ng.'
#         else:
#             error_message = 'L·ªói k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh DB.'
#
#     return render_template('login.html', error=error_message)
#
#
# # --- ROUTE TRANG CH·ª¶ & PH√ÇN LO·∫†I (Gi·ªØ nguy√™n) ---
# @app.route('/trangchu')
# def trangchu_page():
#     if 'loggedin' not in session:
#         return redirect(url_for('login_page'))
#     return render_template('trangchu.html', username=session.get('username'))
#
#
# @app.route('/phan_loai_benh_ga')
# def phan_loai_benh_ga_page():
#     if 'loggedin' not in session:
#         return redirect(url_for('login_page'))
#     return render_template('phan_loai_benh_ga.html', username=session.get('username'))
#
#
# # --- ROUTE X·ª¨ L√ù CH·∫®N ƒêO√ÅN V√Ä KH·ªûI T·∫†O CHAT (T√çCH H·ª¢P RAG) ---
# @app.route('/diagnose', methods=['POST'])
# def diagnose_and_start_chat():
#     """Ch·∫©n ƒëo√°n ·∫£nh, kh·ªüi t·∫°o chat session, v√† tr·∫£ v·ªÅ ph·∫£n h·ªìi RAG ƒë·∫ßu ti√™n."""
#     user_id = session.get('user_id')
#     if not user_id:
#         return jsonify({'error': 'B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ th·ª±c hi·ªán ch·∫©n ƒëo√°n.'}), 401
#
#     if VECTOR_STORE is None:
#         return jsonify({'error': 'H·ªá th·ªëng RAG ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.'}), 500
#
#     try:
#         # 1. Ch·∫©n ƒëo√°n ·∫£nh
#         data = request.get_json()
#         img_data_b64 = data.get('image')
#         if not img_data_b64:
#             return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ·∫£nh (base64).'}), 400
#
#         predicted_name, confidence = process_and_predict(img_data_b64)
#
#         # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p Healthy ho·∫∑c L·ªói d·ª± ƒëo√°n
#         if predicted_name in ["L·ªói x·ª≠ l√Ω", "L·ªói t·∫£i m√¥ h√¨nh"]:
#             return jsonify({
#                 'success': True,
#                 'prediction': {'disease': predicted_name, 'confidence': f'{confidence:.2f}%'},
#                 'initial_chat_response': f"L·ªói h·ªá th·ªëng khi d·ª± ƒëo√°n."
#             })
#
#         if predicted_name == "Healthy":
#             return jsonify({
#                 'success': True,
#                 'prediction': {'disease': predicted_name, 'confidence': f'{confidence:.2f}%'},
#                 'initial_chat_response': f"K·∫øt qu·∫£ ch·∫©n ƒëo√°n: **{predicted_name}**. G√† c·ªßa b·∫°n kh·ªèe m·∫°nh, h√£y ti·∫øp t·ª•c duy tr√¨ ch·∫ø ƒë·ªô chƒÉm s√≥c t·ªët!"
#             })
#
#         # 2. Kh·ªüi t·∫°o Chatbot v√† RAG cho b·ªánh ƒë∆∞·ª£c ch·∫©n ƒëo√°n
#
#         # a. Truy v·∫•n RAG (L·∫•y th√¥ng tin ph√°c ƒë·ªì ban ƒë·∫ßu)
#         query_rag = f"Ph√°c ƒë·ªì ƒëi·ªÅu tr·ªã ban ƒë·∫ßu v√† tri·ªáu ch·ª©ng ch√≠nh c·ªßa b·ªánh {predicted_name}"
#         rag_docs = VECTOR_STORE.similarity_search(query_rag, k=3)
#         rag_context = "\n---\n".join([doc.page_content for doc in rag_docs])
#
#         # b. Thi·∫øt l·∫≠p System Prompt v√† Message
#         system_prompt = (
#             "B·∫°n l√† chuy√™n gia th√∫ y gia c·∫ßm. H√£y cung c·∫•p t∆∞ v·∫•n chi ti·∫øt D·ª∞A TR√äN NG·ªÆ C·∫¢NH "
#             "CHUY√äN M√îN ƒë∆∞·ª£c cung c·∫•p. Tuy·ªát ƒë·ªëi kh√¥ng t·ª± suy di·ªÖn n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu. "
#             "S·ª≠ d·ª•ng Markdown ƒë·ªÉ ƒë·ªãnh d·∫°ng c√¢u tr·∫£ l·ªùi d·ªÖ ƒë·ªçc."
#         )
#         initial_prompt = (
#             f"K·∫øt qu·∫£ ch·∫©n ƒëo√°n h√¨nh ·∫£nh l√† **{predicted_name}** v·ªõi ƒë·ªô tin c·∫≠y {confidence:.2f}%. "
#             f"D∆∞·ªõi ƒë√¢y l√† c√°c d·ªØ li·ªáu chuy√™n m√¥n v·ªÅ b·ªánh n√†y:\n\n"
#             f"--- NGU·ªíN D·ªÆ LI·ªÜU RAG ---\n{rag_context}\n--- END RAG ---\n\n"
#             "D·ª±a v√†o th√¥ng tin tr√™n, h√£y ƒë∆∞a ra: 1. T√≥m t·∫Øt nhanh v·ªÅ b·ªánh. 2. Ph√°c ƒë·ªì ƒëi·ªÅu tr·ªã kh·∫©n c·∫•p ban ƒë·∫ßu (thu·ªëc v√† c√°ch ly)."
#         )
#
#         # c. Kh·ªüi t·∫°o Chat Session v·ªõi System Prompt
#         chat = gemini_client.chats.create(
#             model=LLM_MODEL,
#             config={'system_instruction': system_prompt}
#         )
#
#         # d. G·ª≠i tin nh·∫Øn ƒë·∫ßu ti√™n v√† l∆∞u Session
#         initial_response = chat.send_message(initial_prompt)
#         ACTIVE_CHATS[user_id] = chat  # L∆∞u l·∫°i phi√™n chat
#
#         # 3. Tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON v√† Ph·∫£n h·ªìi Chatbot
#         return jsonify({
#             'success': True,
#             'prediction': {
#                 'disease': predicted_name,
#                 'confidence': f'{confidence:.2f}%'
#             },
#             'initial_chat_response': initial_response.text
#         })
#
#     except Exception as e:
#         print(f"L·ªñI KH·ªûI T·∫†O CHAT V√Ä RAG: {e}")
#         # X√≥a chat session n·∫øu l·ªói
#         if user_id in ACTIVE_CHATS: del ACTIVE_CHATS[user_id]
#         return jsonify({'error': f'L·ªói h·ªá th·ªëng khi kh·ªüi t·∫°o t∆∞ v·∫•n: {str(e)}'}), 500
#
#
# # --- ROUTE X·ª¨ L√ù C√ÇU H·ªéI TI·∫æP THEO ---
# @app.route('/chat', methods=['POST'])
# def handle_followup_chat():
#     """API nh·∫≠n c√¢u h·ªèi ti·∫øp theo, s·ª≠ d·ª•ng RAG v√† phi√™n chat ƒë√£ l∆∞u."""
#     user_id = session.get('user_id')
#     if not user_id:
#         return jsonify({'error': 'B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p.'}), 401
#
#     if user_id not in ACTIVE_CHATS:
#         return jsonify({'error': 'Ch∆∞a c√≥ phi√™n chat n√†o ƒë∆∞·ª£c kh·ªüi t·∫°o. Vui l√≤ng ch·∫©n ƒëo√°n tr∆∞·ªõc.'}), 400
#
#     if VECTOR_STORE is None:
#         return jsonify({'error': 'H·ªá th·ªëng RAG ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.'}), 500
#
#     try:
#         data = request.get_json()
#         user_question = data.get('question')
#
#         if not user_question:
#             return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi.'}), 400
#
#         # L·∫•y phi√™n chat hi·ªán t·∫°i
#         current_chat = ACTIVE_CHATS[user_id]
#
#         # 1. Truy v·∫•n RAG (L·∫•y th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi m·ªõi)
#         rag_docs = VECTOR_STORE.similarity_search(user_question, k=3)
#         rag_context = "\n---\n".join([doc.page_content for doc in rag_docs])
#
#         # 2. G·ªôp RAG v√†o Prompt
#         augmented_prompt = (
#             f"D·ª±a tr√™n NG·ªÆ C·∫¢NH B·ªî SUNG d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi: '{user_question}'. "
#             f"ƒê·∫£m b·∫£o c√¢u tr·∫£ l·ªùi nh·∫•t qu√°n v·ªõi l·ªãch s·ª≠ tr√≤ chuy·ªán (n·∫øu c√≥).\n\n"
#             f"--- NG·ªÆ C·∫¢NH RAG ---\n{rag_context}\n--- END NG·ªÆ C·∫¢NH ---\n"
#         )
#         response = current_chat.send_message(augmented_prompt)
#
#         # 4. Tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON
#         return jsonify({
#             'success': True,
#             'response': response.text
#         })
#
#     except Exception as e:
#         print(f"L·ªñI X·ª¨ L√ù CHAT TI·∫æP THEO: {e}")
#         return jsonify({'error': f'L·ªói server kh√¥ng x√°c ƒë·ªãnh: {str(e)}'}), 500
#
#     # =================================================================
#     # 4. CH·∫†Y ·ª®NG D·ª§NG
#     # =================================================================
#
#     if __name__ == '__main__':
#         app.run(debug=True, host='0.0.0.0', port=5000)
#
#     # 3. G·ª≠i Prompt TƒÉng c∆∞·ªùng ƒë·∫øn Gemini (gi·ªØ l·∫°i l·ªãch s·ª≠ chat)
#
#

#
# import os
# import io
# import re
# import base64
# import numpy as np
# from flask import Flask, render_template, request, redirect, url_for, session, jsonify
# import mysql.connector
#
# # =================================================================
# # IMPORT LANGCHAIN HI·ªÜN ƒê·∫†I
# # =================================================================
# from google import genai
# from langchain_text_splitters import RecursiveCharacterTextSplitter
# from langchain_google_genai import GoogleGenerativeAIEmbeddings
# from langchain_chroma import Chroma
#
# try:
#     import tensorflow as tf
#     from tensorflow.keras.preprocessing import image
# except ImportError:
#     print("!!! L·ªñI: Thi·∫øu th∆∞ vi·ªán AI. Vui l√≤ng c√†i ƒë·∫∑t: pip install tensorflow")
#     tf = None
#
# # =================================================================
# # 0. C·∫§U H√åNH V√Ä KH·ªûI T·∫†O CHUNG
# # =================================================================
#
# # üîë ƒê·∫£m b·∫£o API Key c·ªßa b·∫°n c√≤n ho·∫°t ƒë·ªông
# os.environ["GOOGLE_API_KEY"] = "AIzaSyCifSb7b1ldIDPiSn7Gz2ZCmTm6HtaLbr0"
# EMBEDDING_MODEL = "text-embedding-004"
# LLM_MODEL = "gemini-2.0-flash"  # S·ª≠ d·ª•ng model flash m·ªõi nh·∫•t
#
# try:
#     gemini_client = genai.Client()
# except Exception as e:
#     print(f"!!! L·ªñI KH·ªûI T·∫†O GEMINI CLIENT: {e}")
#
# VECTOR_STORE = None
# ACTIVE_CHATS = {}
#
# DB_CONFIG = {
#     'host': 'localhost',
#     'user': 'root',
#     'password': '123456',
#     'database': 'benh_ga'
# }
#
# MODEL_PATH = r'D:\Hoc Ki Cuoi\Web_Chicken\web\model\best_model.keras'
# CLASS_NAMES = ['B·ªánh C·∫ßu Tr√πng G√† (Coccidiosis)', 'Healthy', 'B·ªánh Newcastle (G√† R√π)', 'Salmonella']
# IMG_HEIGHT = 224
# IMG_WIDTH = 224
#
# app = Flask(__name__)
# app.secret_key = 'mot_chuoi_bi_mat_rat_dai_va_kho'
#
# # T·∫¢I M√î H√åNH
# model = None
# if tf is not None:
#     try:
#         model = tf.keras.models.load_model(MODEL_PATH)
#         print(f">>> ‚úÖ M√¥ h√¨nh AI ƒë√£ t·∫£i th√†nh c√¥ng.")
#     except Exception as e:
#         print(f"!!! L·ªñI T·∫¢I M√î H√åNH: {e}")
#
#
# # =================================================================
# # 1. H√ÄM DATABASE V√Ä RAG
# # =================================================================
#
# def get_db_connection():
#     try:
#         conn = mysql.connector.connect(**DB_CONFIG)
#         return conn
#     except mysql.connector.Error as err:
#         print(f"L·ªói k·∫øt n·ªëi database: {err}")
#         return None
#
#
# def load_and_chunk_data():
#     global VECTOR_STORE
#     if VECTOR_STORE is not None: return
#
#     conn = get_db_connection()
#     if not conn: return
#
#     try:
#         cursor = conn.cursor(dictionary=True)
#         query = "SELECT ten_benh, dulieubenh FROM benh"
#         cursor.execute(query)
#         data = cursor.fetchall()
#         cursor.close()
#         conn.close()
#
#         texts = []
#         for row in data:
#             full_text = f"B·ªánh: {row['ten_benh']}\nN·ªôi dung: {row['dulieubenh']}"
#             texts.append(full_text)
#
#         text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=80)
#         chunks = text_splitter.create_documents(texts)
#
#         embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
#         VECTOR_STORE = Chroma.from_documents(chunks, embeddings)
#         print(">>> ‚úÖ RAG Vector Store s·∫µn s√†ng.")
#     except Exception as e:
#         print(f"!!! L·ªñI RAG: {e}")
#
#
# @app.before_request
# def initialize_rag():
#     if VECTOR_STORE is None:
#         load_and_chunk_data()
#
#
# # =================================================================
# # 2. X·ª¨ L√ù CH·∫®N ƒêO√ÅN (ƒê√É S·ª¨A THEO √ù B·∫†N)
# # =================================================================
#
# def process_and_predict(base64_img_string):
#     if model is None: return "L·ªói t·∫£i m√¥ h√¨nh", 0.0
#     try:
#         img_data = re.sub('^data:image/.+;base64,', '', base64_img_string)
#         img_bytes = base64.b64decode(img_data)
#         img = image.load_img(io.BytesIO(img_bytes), target_size=(IMG_HEIGHT, IMG_WIDTH))
#         x = image.img_to_array(img) / 255.0
#         x = np.expand_dims(x, axis=0)
#         predictions = model.predict(x)
#         idx = np.argmax(predictions[0])
#         return CLASS_NAMES[idx], np.max(predictions[0]) * 100
#     except Exception as e:
#         return f"L·ªói: {str(e)}", 0.0
#
#
# @app.route('/diagnose', methods=['POST'])
# def diagnose_and_start_chat():
#     user_id = session.get('user_id')
#     if not user_id: return jsonify({'error': 'Ch∆∞a ƒëƒÉng nh·∫≠p'}), 401
#
#     try:
#         data = request.get_json()
#         predicted_name, confidence = process_and_predict(data.get('image'))
#
#         if predicted_name == "Healthy":
#             return jsonify({
#                 'success': True,
#                 'prediction': {'disease': 'Kh·ªèe m·∫°nh', 'confidence': f'{confidence:.2f}%'},
#                 'initial_chat_response': "G√† c·ªßa b·∫°n c√≥ v·∫ª r·∫•t kh·ªèe m·∫°nh! H√£y ti·∫øp t·ª•c duy tr√¨ ch·∫ø ƒë·ªô dinh d∆∞·ª°ng t·ªët nh√©."
#             })
#
#         # --- PH·∫¶N THAY ƒê·ªîI: H·ªéI √ù KI·∫æN TR∆Ø·ªöC ---
#                 system_prompt = (
#                     "B·∫†N L√Ä CHUY√äN GIA TH√ö Y G√Ä - TR·ª¢ L√ù ƒê·∫ÆC L·ª∞C C·ª¶A WEB CHICKEN AI.\n\n"
#
#                     "K·ª∂ LU·∫¨T TR·∫¢ L·ªúI (NGHI√äM NG·∫∂T):\n"
#                     "1. CH·ªà TR·∫¢ L·ªúI d·ª±a tr√™n th√¥ng tin c√≥ trong 'D·ªÆ LI·ªÜU TH√ö Y' ƒë∆∞·ª£c cung c·∫•p. Tuy·ªát ƒë·ªëi kh√¥ng t·ª± b·ªãa ra ki·∫øn th·ª©c ngo√†i.\n"
#                     "2. PH√ÇN BI·ªÜT B·ªÜNH: N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ 'Newcastle' ho·∫∑c 'G√† r√π', CH·ªà l·∫•y d·ªØ li·ªáu c·ªßa Newcastle. N·∫øu h·ªèi 'C·∫ßu tr√πng', CH·ªà l·∫•y d·ªØ li·ªáu C·∫ßu tr√πng. Kh√¥ng ƒë∆∞·ª£c tr·∫£ l·ªùi nh·∫ßm n·ªôi dung b·ªánh n√†y cho b·ªánh kia.\n"
#                     "3. X√ÅC NH·∫¨N T√äN: Hi·ªÉu r·∫±ng 'New Castle Disease', 'Newcastle' v√† 'G√† R√π' l√† c√πng m·ªôt b·ªánh.\n"
#                     "4. N·∫øu th√¥ng tin trong Database b·ªã thi·∫øu ho·∫∑c l√† NULL, h√£y b√°o: 'Xin l·ªói, hi·ªán t·∫°i h·ªá th·ªëng ch∆∞a c·∫≠p nh·∫≠t chi ti·∫øt m·ª•c n√†y cho b·ªánh [T√™n b·ªánh].'\n\n"
#
#                     "QUY ƒê·ªäNH TR√åNH B√ÄY (ƒê·ªÇ KH√îNG B·ªä R·ªêI):\n"
#                     "- TUY·ªÜT ƒê·ªêI KH√îNG s·ª≠ d·ª•ng c√°c k√Ω t·ª±: * (d·∫•u sao), # (d·∫•u thƒÉng), ** (in ƒë·∫≠m).\n"
#                     "- S·ª¨ D·ª§NG CH·ªÆ VI·∫æT HOA C√ì D·∫§U cho c√°c ti√™u ƒë·ªÅ m·ª•c l·ªõn (V√≠ d·ª•: NGUY√äN NH√ÇN, TRI·ªÜU CH·ª®NG, ƒêI·ªÄU TR·ªä).\n"
#                     "- M·ªói √Ω con b·∫Øt bu·ªôc ph·∫£i xu·ªëng d√≤ng v√† b·∫Øt ƒë·∫ßu b·∫±ng d·∫•u g·∫°ch ngang (-).\n"
#                     "- GI·ªÆA C√ÅC M·ª§C L·ªöN PH·∫¢I C√ÅCH NHAU 1 D√íNG TR·ªêNG (d√πng hai d·∫•u xu·ªëng d√≤ng \\n\\n).\n"
#                     "- Tr√¨nh b√†y theo d·∫°ng danh s√°ch, kh√¥ng vi·∫øt th√†nh m·ªôt kh·ªëi vƒÉn b·∫£n d√†i d·∫∑c.\n\n"
#
#                     "PHONG C√ÅCH: Chuy√™n nghi·ªáp, ng·∫Øn g·ªçn, ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ h·ªó tr·ª£ ng∆∞·ªùi chƒÉn nu√¥i."
#                 )
#
#         # T·∫°o phi√™n chat m·ªõi
#         chat = gemini_client.chats.create(model=LLM_MODEL, config={'system_instruction': system_prompt})
#         ACTIVE_CHATS[user_id] = chat
#
#         # C√¢u ch√†o h·ªèi ƒë·∫ßu ti√™n (Kh√¥ng ƒë∆∞a ph√°c ƒë·ªì ngay)
#         initial_greeting = (
#             f"D·ª±a tr√™n h√¨nh ·∫£nh, t√¥i ch·∫©n ƒëo√°n g√† c√≥ kh·∫£ nƒÉng cao m·∫Øc b·ªánh **{predicted_name}** ({confidence:.2f}%). "
#             f"\n\nCh√†o b·∫°n, t√¥i r·∫•t ti·∫øc khi bi·∫øt g√† c·ªßa b·∫°n c√≥ d·∫•u hi·ªáu m·∫Øc b·ªánh n√†y. "
#             f"B·∫°n c√≥ mu·ªën t√¥i gi√∫p b·∫°n t√¨m hi·ªÉu chi ti·∫øt v·ªÅ c√°c tri·ªáu ch·ª©ng v√† cung c·∫•p ph√°c ƒë·ªì ƒëi·ªÅu tr·ªã cho b·ªánh {predicted_name} ngay kh√¥ng?"
#         )
#
#         return jsonify({
#             'success': True,
#             'prediction': {'disease': predicted_name, 'confidence': f'{confidence:.2f}%'},
#             'initial_chat_response': initial_greeting
#         })
#
#     except Exception as e:
#         return jsonify({'error': str(e)}), 500
#
#
# # =================================================================
# # 3. CHAT TI·∫æP THEO (KHI NG∆Ø·ªúI D√ôNG ƒê·ªíNG √ù)
# # =================================================================
#
# @app.route('/chat', methods=['POST'])
# def handle_followup_chat():
#     user_id = session.get('user_id')
#     current_chat = ACTIVE_CHATS.get(user_id)
#     if not current_chat: return jsonify({'error': 'Phi√™n chat h·∫øt h·∫°n'}), 400
#
#     try:
#         data = request.get_json()
#         user_question = data.get('question')
#
#         # Truy v·∫•n RAG ƒë·ªÉ l·∫•y ki·∫øn th·ª©c t·ª´ Database
#         rag_docs = VECTOR_STORE.similarity_search(user_question, k=3)
#         rag_context = "\n---\n".join([doc.page_content for doc in rag_docs])
#
#         # G·ª≠i k√®m ng·ªØ c·∫£nh cho AI
#         full_prompt = (
#             f"S·ª≠ d·ª•ng th√¥ng tin sau ƒë·ªÉ tr·∫£ l·ªùi ng∆∞·ªùi d√πng: \n{rag_context}\n\n"
#             f"C√¢u h·ªèi: {user_question}"
#         )
#         response = current_chat.send_message(full_prompt)
#
#         return jsonify({'success': True, 'response': response.text})
#     except Exception as e:
#         return jsonify({'error': str(e)}), 500
#
#
# # C√°c route login/trang chu gi·ªØ nguy√™n c·ªßa b·∫°n...
# @app.route('/', methods=['GET', 'POST'])
# @app.route('/login', methods=['GET', 'POST'])
# def login_page():
#     if request.method == 'POST':
#         taikhoan, mk = request.form.get('taikhoan'), request.form.get('mk')
#         conn = get_db_connection()
#         if conn:
#             cursor = conn.cursor(dictionary=True)
#             cursor.execute("SELECT idTaikhoan, taikhoan FROM user WHERE taikhoan = %s AND matkhau = %s", (taikhoan, mk))
#             user = cursor.fetchone()
#             conn.close()
#             if user:
#                 session['loggedin'], session['user_id'], session['username'] = True, user['idTaikhoan'], user[
#                     'taikhoan']
#                 return redirect(url_for('trangchu_page'))
#     return render_template('login.html')
#
#
# @app.route('/trangchu')
# def trangchu_page():
#     if 'loggedin' not in session: return redirect(url_for('login_page'))
#     return render_template('trangchu.html', username=session.get('username'))
#
#
# @app.route('/phan_loai_benh_ga')
# def phan_loai_benh_ga_page():
#     if 'loggedin' not in session: return redirect(url_for('login_page'))
#     return render_template('phan_loai_benh_ga.html', username=session.get('username'))
#
#
# if __name__ == '__main__':
#     app.run(debug=True, host='0.0.0.0', port=5000)


# import os
# import io
# import re
# import base64
# import numpy as np
# from flask import Flask, render_template, request, redirect, url_for, session, jsonify
# import mysql.connector
#
# # =================================================================
# # IMPORT AI & RAG TOOLKIT
# # =================================================================
# from google import genai
# from langchain_text_splitters import RecursiveCharacterTextSplitter
# from langchain_google_genai import GoogleGenerativeAIEmbeddings
# from langchain_chroma import Chroma
#
# try:
#     import tensorflow as tf
#     from tensorflow.keras.preprocessing import image
# except ImportError:
#     print("!!! L·ªñI: Thi·∫øu th∆∞ vi·ªán AI. Vui l√≤ng c√†i ƒë·∫∑t: pip install tensorflow")
#     tf = None
#
# # =================================================================
# # 0. C·∫§U H√åNH H·ªÜ TH·ªêNG
# # =================================================================
#
# # üîë API Key v√† Model config
# os.environ["GOOGLE_API_KEY"] = "AIzaSyCifSb7b1ldIDPiSn7Gz2ZCmTm6HtaLbr0"
# EMBEDDING_MODEL = "text-embedding-004"
# LLM_MODEL = "gemini-2.0-flash"
#
# try:
#     gemini_client = genai.Client()
# except Exception as e:
#     print(f"!!! L·ªñI KH·ªûI T·∫†O GEMINI CLIENT: {e}")
#
# VECTOR_STORE = None
# ACTIVE_CHATS = {}
#
# DB_CONFIG = {
#     'host': 'localhost',
#     'user': 'root',
#     'password': '123456',
#     'database': 'benh_ga'
# }
#
# MODEL_PATH = r'D:\Hoc Ki Cuoi\Web_Chicken\web\model\best_model.keras'
# # S·ª≠a l·∫°i cho kh·ªõp v·ªõi c·ªôt ten_benh trong DB
# CLASS_NAMES = ['B·ªánh C·∫ßu Tr√πng G√† (Coccidiosis)', 'Healthy', 'B·ªánh Newcastle (G√† R√π)', 'Salmonella']
# IMG_HEIGHT = 224
# IMG_WIDTH = 224
#
# app = Flask(__name__)
# app.secret_key = 'capstone_chicken_ai_key_secret'
#
# # T·∫¢I M√î H√åNH CH·∫®N ƒêO√ÅN ·∫¢NH
# model = None
# if tf is not None:
#     try:
#         model = tf.keras.models.load_model(MODEL_PATH)
#         print(f">>> ‚úÖ M√¥ h√¨nh AI Ch·∫©n ƒëo√°n ƒë√£ s·∫µn s√†ng.")
#     except Exception as e:
#         print(f"!!! L·ªñI T·∫¢I M√î H√åNH: {e}")
#
# # =================================================================
# # 1. QU·∫¢N L√ù DATABASE & RAG (K·ª∏ THU·∫¨T T·ªêI ∆ØU)
# # =================================================================
#
# def get_db_connection():
#     try:
#         conn = mysql.connector.connect(**DB_CONFIG)
#         return conn
#     except mysql.connector.Error as err:
#         print(f"L·ªói k·∫øt n·ªëi database: {err}")
#         return None
#
# def load_and_chunk_data():
#     """ƒê·ªçc d·ªØ li·ªáu t·ª´ 6 c·ªôt MySQL v√† n·∫°p v√†o Vector Database"""
#     global VECTOR_STORE
#     if VECTOR_STORE is not None: return
#
#     conn = get_db_connection()
#     if not conn: return
#
#     try:
#         cursor = conn.cursor(dictionary=True)
#         # üü¢ TRUY V·∫§N T·∫§T C·∫¢ C·ªòT CHI TI·∫æT
#         query = "SELECT ten_benh, mo_ta_benh, nguyen_nhan, trieu_chung, phong_benh, dieu_tri_vac_xin FROM benh"
#         cursor.execute(query)
#         data = cursor.fetchall()
#         cursor.close()
#         conn.close()
#
#         texts = []
#         for row in data:
#             # G·∫Øn nh√£n r√µ r√†ng ƒë·ªÉ Vector Store t√¨m ki·∫øm theo ng·ªØ c·∫£nh t·ªët h∆°n
#             full_content = (
#                 f"B·ªÜNH: {row['ten_benh']}\n"
#                 f"M√î T·∫¢: {row['mo_ta_benh']}\n"
#                 f"NGUY√äN NH√ÇN: {row['nguyen_nhan']}\n"
#                 f"TRI·ªÜU CH·ª®NG: {row['trieu_chung']}\n"
#                 f"PH√íNG B·ªÜNH: {row['phong_benh']}\n"
#                 f"ƒêI·ªÄU TR·ªä & VACCINE: {row['dieu_tri_vac_xin']}"
#             )
#             texts.append(full_content)
#
#         # Chunk size 1200 gi√∫p gi·ªØ tr·ªçn v·∫πn th√¥ng tin m·ªôt th·ªÉ b·ªánh
#         text_splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=150)
#         chunks = text_splitter.create_documents(texts)
#
#         embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
#         VECTOR_STORE = Chroma.from_documents(
#             documents=chunks,
#             embedding=embeddings,
#             persist_directory="./chroma_db" # L∆∞u l·∫°i ƒë·ªÉ kh√¥ng ph·∫£i load nhi·ªÅu l·∫ßn
#         )
#         print(">>> ‚úÖ Vector Store ƒë√£ n·∫°p d·ªØ li·ªáu chi ti·∫øt th√†nh c√¥ng.")
#     except Exception as e:
#         print(f"!!! L·ªñI RAG: {e}")
#
# @app.before_request
# def initialize_rag():
#     if VECTOR_STORE is None:
#         load_and_chunk_data()
#
# # =================================================================
# # 2. X·ª¨ L√ù CH·∫®N ƒêO√ÅN V√Ä CHAT KH·ªûI T·∫†O
# # =================================================================
#
# def process_and_predict(base64_img_string):
#     if model is None: return "L·ªói h·ªá th·ªëng", 0.0
#     try:
#         img_data = re.sub('^data:image/.+;base64,', '', base64_img_string)
#         img_bytes = base64.b64decode(img_data)
#         img = image.load_img(io.BytesIO(img_bytes), target_size=(IMG_HEIGHT, IMG_WIDTH))
#         x = image.img_to_array(img) / 255.0
#         x = np.expand_dims(x, axis=0)
#         predictions = model.predict(x)
#         idx = np.argmax(predictions[0])
#         return CLASS_NAMES[idx], np.max(predictions[0]) * 100
#     except Exception as e:
#         return f"L·ªói: {str(e)}", 0.0
#
# @app.route('/diagnose', methods=['POST'])
# def diagnose_and_start_chat():
#     user_id = session.get('user_id')
#     if not user_id: return jsonify({'error': 'Vui l√≤ng ƒëƒÉng nh·∫≠p'}), 401
#
#     try:
#         data = request.get_json()
#         predicted_name, confidence = process_and_predict(data.get('image'))
#
#         if predicted_name == "Healthy":
#             return jsonify({
#                 'success': True,
#                 'prediction': {'disease': 'Kh·ªèe m·∫°nh', 'confidence': f'{confidence:.2f}%'},
#                 'initial_chat_response': "Tuy·ªát v·ªùi! K·∫øt qu·∫£ cho th·∫•y g√† c·ªßa b·∫°n kh·ªèe m·∫°nh. H√£y duy tr√¨ v·ªá sinh chu·ªìng tr·∫°i nh√©!"
#             })
#
#         # Thi·∫øt l·∫≠p System Instruction cho b√°c sƒ© AI
#         # System prompt m·ªõi √©p AI kh√¥ng d√πng d·∫•u sao
#         system_prompt = (
#             "B·∫†N L√Ä CHUY√äN GIA TH√ö Y G√Ä - TR·ª¢ L√ù ƒê·∫ÆC L·ª∞C C·ª¶A WEB CHICKEN AI.\n\n"
#
#             "K·ª∂ LU·∫¨T TR·∫¢ L·ªúI (NGHI√äM NG·∫∂T):\n"
#             "1. CH·ªà TR·∫¢ L·ªúI d·ª±a tr√™n th√¥ng tin c√≥ trong 'D·ªÆ LI·ªÜU TH√ö Y' ƒë∆∞·ª£c cung c·∫•p. Tuy·ªát ƒë·ªëi kh√¥ng t·ª± b·ªãa ra ki·∫øn th·ª©c ngo√†i.\n"
#             "2. PH√ÇN BI·ªÜT B·ªÜNH: N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ 'Newcastle' ho·∫∑c 'G√† r√π', CH·ªà l·∫•y d·ªØ li·ªáu c·ªßa Newcastle. N·∫øu h·ªèi 'C·∫ßu tr√πng', CH·ªà l·∫•y d·ªØ li·ªáu C·∫ßu tr√πng. Kh√¥ng ƒë∆∞·ª£c tr·∫£ l·ªùi nh·∫ßm n·ªôi dung b·ªánh n√†y cho b·ªánh kia.\n"
#             "3. X√ÅC NH·∫¨N T√äN: Hi·ªÉu r·∫±ng 'New Castle Disease', 'Newcastle' v√† 'G√† R√π' l√† c√πng m·ªôt b·ªánh.\n"
#             "4. N·∫øu th√¥ng tin trong Database b·ªã thi·∫øu ho·∫∑c l√† NULL, h√£y b√°o: 'Xin l·ªói, hi·ªán t·∫°i h·ªá th·ªëng ch∆∞a c·∫≠p nh·∫≠t chi ti·∫øt m·ª•c n√†y cho b·ªánh [T√™n b·ªánh].'\n\n"
#
#             "QUY ƒê·ªäNH TR√åNH B√ÄY (ƒê·ªÇ KH√îNG B·ªä R·ªêI):\n"
#             "- TUY·ªÜT ƒê·ªêI KH√îNG s·ª≠ d·ª•ng c√°c k√Ω t·ª±: * (d·∫•u sao), # (d·∫•u thƒÉng), ** (in ƒë·∫≠m).\n"
#             "- S·ª¨ D·ª§NG CH·ªÆ VI·∫æT HOA C√ì D·∫§U cho c√°c ti√™u ƒë·ªÅ m·ª•c l·ªõn (V√≠ d·ª•: NGUY√äN NH√ÇN, TRI·ªÜU CH·ª®NG, ƒêI·ªÄU TR·ªä).\n"
#             "- M·ªói √Ω con b·∫Øt bu·ªôc ph·∫£i xu·ªëng d√≤ng v√† b·∫Øt ƒë·∫ßu b·∫±ng d·∫•u g·∫°ch ngang (-).\n"
#             "- GI·ªÆA C√ÅC M·ª§C L·ªöN PH·∫¢I C√ÅCH NHAU 1 D√íNG TR·ªêNG (d√πng hai d·∫•u xu·ªëng d√≤ng \\n\\n).\n"
#             "- Tr√¨nh b√†y theo d·∫°ng danh s√°ch, kh√¥ng vi·∫øt th√†nh m·ªôt kh·ªëi vƒÉn b·∫£n d√†i d·∫∑c.\n\n"
#
#             "PHONG C√ÅCH: Chuy√™n nghi·ªáp, ng·∫Øn g·ªçn, ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ h·ªó tr·ª£ ng∆∞·ªùi chƒÉn nu√¥i."
#         )
#
#         chat = gemini_client.chats.create(model=LLM_MODEL, config={'system_instruction': system_prompt})
#         ACTIVE_CHATS[user_id] = chat
#
#         initial_greeting = (
#             f"T√¥i ch·∫©n ƒëo√°n g√† c√≥ kh·∫£ nƒÉng cao m·∫Øc b·ªánh **{predicted_name}** ({confidence:.2f}%). "
#             f"\n\nCh√†o b·∫°n, ƒë√¢y l√† m·ªôt b·ªánh c·∫ßn can thi·ªáp s·ªõm. "
#             f"B·∫°n c√≥ mu·ªën t√¥i li·ªát k√™ chi ti·∫øt tri·ªáu ch·ª©ng v√† ph√°c ƒë·ªì ƒëi·ªÅu tr·ªã t·ª´ c∆° s·ªü d·ªØ li·ªáu cho b·∫°n kh√¥ng?"
#         )
#
#         return jsonify({
#             'success': True,
#             'prediction': {'disease': predicted_name, 'confidence': f'{confidence:.2f}%'},
#             'initial_chat_response': initial_greeting
#         })
#
#     except Exception as e:
#         return jsonify({'error': str(e)}), 500
#
# # =================================================================
# # 3. H√ÄM CHAT RAG (TRUY XU·∫§T TH√îNG TIN CHUY√äN S√ÇU)
# # =================================================================
#
# @app.route('/chat', methods=['POST'])
# def handle_followup_chat():
#     user_id = session.get('user_id')
#     current_chat = ACTIVE_CHATS.get(user_id)
#     if not current_chat: return jsonify({'error': 'Phi√™n chat ƒë√£ k·∫øt th√∫c'}), 400
#
#     try:
#         data = request.get_json()
#         user_question = data.get('question')
#
#         # üîç TRUY XU·∫§T RAG (T√¨m ki·∫øm th√¥ng tin t·ª´ 6 c·ªôt ƒë√£ n·∫°p)
#         # S·ª≠ d·ª•ng similarity_search ƒë·ªÉ b·ªëc ra ƒë√∫ng ƒëo·∫°n m√¥ t·∫£ tri·ªáu ch·ª©ng/thu·ªëc
#         rag_docs = VECTOR_STORE.similarity_search(user_question, k=4)
#         rag_context = "\n---\n".join([doc.page_content for doc in rag_docs])
#
#         # K·∫øt h·ª£p c√¢u h·ªèi ng∆∞·ªùi d√πng v√† ng·ªØ c·∫£nh t·ª´ DB
#         full_prompt = (
#             f"D·ª∞A V√ÄO TH√îNG TIN CHUY√äN M√îN SAU:\n{rag_context}\n\n"
#             f"C√ÇU H·ªéI NG∆Ø·ªúI D√ôNG: {user_question}\n\n"
#             f"H√ÉY TR·∫¢ L·ªúI: D·ª±a ho√†n to√†n v√†o d·ªØ li·ªáu tr√™n ƒë·ªÉ t∆∞ v·∫•n cho ng∆∞·ªùi d√πng. "
#             f"N·∫øu c√¢u h·ªèi v·ªÅ thu·ªëc ho·∫∑c vaccine, h√£y li·ªát k√™ r√µ r√†ng t√™n thu·ªëc."
#         )
#         response = current_chat.send_message(full_prompt)
#
#         return jsonify({'success': True, 'response': response.text})
#     except Exception as e:
#         return jsonify({'error': str(e)}), 500
#
# # =================================================================
# # 4. QU·∫¢N L√ù GIAO DI·ªÜN & LOGIN
# # =================================================================
#
# @app.route('/', methods=['GET', 'POST'])
# @app.route('/login', methods=['GET', 'POST'])
# def login_page():
#     if request.method == 'POST':
#         taikhoan = request.form.get('taikhoan')
#         mk = request.form.get('mk')
#         conn = get_db_connection()
#         if conn:
#             cursor = conn.cursor(dictionary=True)
#             cursor.execute("SELECT idTaikhoan, taikhoan FROM user WHERE taikhoan = %s AND matkhau = %s", (taikhoan, mk))
#             user = cursor.fetchone()
#             conn.close()
#             if user:
#                 session['loggedin'] = True
#                 session['user_id'] = user['idTaikhoan']
#                 session['username'] = user['taikhoan']
#                 return redirect(url_for('trangchu_page'))
#     return render_template('login.html')
#
# @app.route('/trangchu')
# def trangchu_page():
#     if 'loggedin' not in session: return redirect(url_for('login_page'))
#     return render_template('trangchu.html', username=session.get('username'))
#
# @app.route('/phan_loai_benh_ga')
# def phan_loai_benh_ga_page():
#     if 'loggedin' not in session: return redirect(url_for('login_page'))
#     return render_template('phan_loai_benh_ga.html', username=session.get('username'))
#
# @app.route('/logout')
# def logout():
#     session.clear()
#     return redirect(url_for('login_page'))
#
# if __name__ == '__main__':
#     # L∆∞u √Ω: Ch·∫°y host 0.0.0.0 ƒë·ªÉ c√≥ th·ªÉ truy c·∫≠p t·ª´ thi·∫øt b·ªã kh√°c trong m·∫°ng LAN
#     app.run(debug=True, host='0.0.0.0', port=5000)


import os
import io
import re
import base64
import numpy as np
from flask import Flask, render_template, request, redirect, url_for, session, jsonify
import mysql.connector

# =================================================================
# IMPORT AI & RAG TOOLKIT
# =================================================================
from google import genai
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma

try:
    import tensorflow as tf
    from tensorflow.keras.preprocessing import image
except ImportError:
    print("!!! L·ªñI: Thi·∫øu th∆∞ vi·ªán AI. Vui l√≤ng c√†i ƒë·∫∑t: pip install tensorflow")
    tf = None

# =================================================================
# 0. C·∫§U H√åNH H·ªÜ TH·ªêNG
# =================================================================

os.environ["GOOGLE_API_KEY"] = ""
EMBEDDING_MODEL = "text-embedding-004"
LLM_MODEL = "gemini-2.0-flash"

try:
    gemini_client = genai.Client()
except Exception as e:
    print(f"!!! L·ªñI KH·ªûI T·∫†O GEMINI CLIENT: {e}")

VECTOR_STORE = None
ACTIVE_CHATS = {}

DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': '123456',
    'database': 'benh_ga'
}

MODEL_PATH = r'D:\Hoc Ki Cuoi\Web_Chicken\web\model\best_model.keras'
# ‚úÖ T√™n class kh·ªõp 100% v·ªõi c·ªôt ten_benh trong MySQL
# ƒê·∫£m b·∫£o th·ª© t·ª± n√†y kh·ªõp v·ªõi th·ª© t·ª± c√°c Class khi b·∫°n Train Model
# Th·ª© t·ª± chu·∫©n ƒë·ªÉ kh·ªõp v·ªõi Label c·ªßa Model AI
CLASS_NAMES = ['B·ªánh C·∫ßu Tr√πng', 'G√† Kh·ªèe M·∫°nh', 'B·ªánh G√† R√π', 'B·ªánh Th∆∞∆°ng H√†n']
IMG_HEIGHT = 224
IMG_WIDTH = 224

app = Flask(__name__)
app.secret_key = 'capstone_chicken_ai_key_secret'

model = None
if tf is not None:
    try:
        model = tf.keras.models.load_model(MODEL_PATH)
        print(f">>> ‚úÖ M√¥ h√¨nh AI Ch·∫©n ƒëo√°n s·∫µn s√†ng.")
    except Exception as e:
        print(f"!!! L·ªñI T·∫¢I M√î H√åNH: {e}")


# =================================================================
# 1. QU·∫¢N L√ù DATABASE & RAG (C·∫§U TR√öC 3 C·ªòT)
# =================================================================

def get_db_connection():
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        return conn
    except mysql.connector.Error as err:
        print(f"L·ªói k·∫øt n·ªëi database: {err}")
        return None


# def load_and_chunk_data():
#     """ƒê·ªçc d·ªØ li·ªáu t·ª´ 3 c·ªôt MySQL v√† n·∫°p v√†o Vector Database"""
#     global VECTOR_STORE
#     if VECTOR_STORE is not None: return
#
#     conn = get_db_connection()
#     if not conn: return
#
#     try:
#         cursor = conn.cursor(dictionary=True)
#         # üü¢ QUAY L·∫†I TRUY V·∫§N 3 C·ªòT C≈®
#         query = "SELECT ten_benh, dulieubenh FROM benh"
#         cursor.execute(query)
#         data = cursor.fetchall()
#         cursor.close()
#         conn.close()
#
#         texts = []
#         for row in data:
#             full_content = f"B·ªÜNH: {row['ten_benh']}\nN·ªòI DUNG: {row['dulieubenh']}"
#             texts.append(full_content)
#
#         text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
#         chunks = text_splitter.create_documents(texts)
#
#         embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
#         VECTOR_STORE = Chroma.from_documents(
#             documents=chunks,
#             embedding=embeddings,
#             persist_directory="./chroma_db"
#         )
#         print(">>> ‚úÖ RAG Vector Store (3 c·ªôt) ƒë√£ n·∫°p th√†nh c√¥ng.")
#     except Exception as e:
#         print(f"!!! L·ªñI RAG: {e}")
def load_and_chunk_data():
    global VECTOR_STORE
    # B·ªè d√≤ng check None ƒë·ªÉ c√≥ th·ªÉ n·∫°p l·∫°i khi c·∫ßn
    conn = get_db_connection()
    if not conn: return

    try:
        cursor = conn.cursor(dictionary=True)
        query = "SELECT ten_benh, dulieubenh FROM benh"
        cursor.execute(query)
        data = cursor.fetchall()
        cursor.close()
        conn.close()

        documents = []
        for row in data:
            # ‚úÖ QUAN TR·ªåNG: L·∫∑p l·∫°i t√™n b·ªánh ·ªü ƒë·∫ßu m·ªói ƒëo·∫°n d·ªØ li·ªáu
            # ƒêi·ªÅu n√†y gi√∫p Vector c·ªßa "G√† R√π" s·∫Ω kh√°c h·∫≥n Vector c·ªßa "C·∫ßu Tr√πng"
            content = f"TH√îNG TIN V·ªÄ {row['ten_benh'].upper()}: {row['dulieubenh']}"

            # Chia nh·ªè d·ªØ li·ªáu nh∆∞ng v·∫´n gi·ªØ ng·ªØ c·∫£nh t√™n b·ªánh
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=50)
            chunks = text_splitter.split_text(content)

            from langchain_core.documents import Document
            for chunk in chunks:
                documents.append(Document(page_content=chunk, metadata={"source": row['ten_benh']}))

        embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
        VECTOR_STORE = Chroma.from_documents(
            documents=documents,
            embedding=embeddings,
            persist_directory="./chroma_db"
        )
        print(">>> ‚úÖ RAG ƒë√£ n·∫°p d·ªØ li·ªáu ƒë·ªãnh danh b·ªánh th√†nh c√¥ng.")
    except Exception as e:
        print(f"!!! L·ªñI RAG: {e}")


@app.before_request
def initialize_rag():
    if VECTOR_STORE is None:
        load_and_chunk_data()


# =================================================================
# 2. CH·∫®N ƒêO√ÅN V√Ä CHAT KH·ªûI T·∫†O
# =================================================================

def process_and_predict(base64_img_string):
    if model is None: return "L·ªói h·ªá th·ªëng", 0.0
    try:
        img_data = re.sub('^data:image/.+;base64,', '', base64_img_string)
        img_bytes = base64.b64decode(img_data)
        img = image.load_img(io.BytesIO(img_bytes), target_size=(IMG_HEIGHT, IMG_WIDTH))
        x = image.img_to_array(img) / 255.0
        x = np.expand_dims(x, axis=0)
        predictions = model.predict(x)
        idx = np.argmax(predictions[0])
        return CLASS_NAMES[idx], np.max(predictions[0]) * 100
    except Exception as e:
        return f"L·ªói: {str(e)}", 0.0


@app.route('/diagnose', methods=['POST'])
def diagnose_and_start_chat():
    user_id = session.get('user_id')
    if not user_id: return jsonify({'error': 'Vui l√≤ng ƒëƒÉng nh·∫≠p'}), 401

    try:
        data = request.get_json()
        predicted_name, confidence = process_and_predict(data.get('image'))

        if predicted_name == "Healthy":
            return jsonify({
                'success': True,
                'prediction': {'disease': 'Kh·ªèe m·∫°nh', 'confidence': f'{confidence:.2f}%'},
                'initial_chat_response': "Tuy·ªát v·ªùi! K·∫øt qu·∫£ cho th·∫•y g√† kh·ªèe m·∫°nh. H√£y duy tr√¨ v·ªá sinh chu·ªìng tr·∫°i nh√©!"
            })

        # system_prompt = (
        #     "B·∫†N L√Ä CHUY√äN GIA TH√ö Y G√Ä - TR·ª¢ L√ù C·ª¶A WEB CHICKEN AI.\n\n"
        #
        #     "K·ª∂ LU·∫¨T TR·∫¢ L·ªúI:\n"
        #     "1. ∆ØU TI√äN s·ª≠ d·ª•ng th√¥ng tin trong 'D·ªÆ LI·ªÜU TH√ö Y'. N·∫øu d·ªØ li·ªáu b·ªã thi·∫øu m·ªôt ph·∫ßn, h√£y s·ª≠ d·ª•ng ki·∫øn th·ª©c chuy√™n m√¥n th√∫ y ƒë·ªÉ b·ªï sung sao cho ch√≠nh x√°c nh·∫•t, tuy·ªát ƒë·ªëi kh√¥ng tr·∫£ l·ªùi sai ki·∫øn th·ª©c y khoa.\n"
        #     "2. NG·ªÆ C·∫¢NH: Hi·ªÉu r·∫±ng Newcastle v√† G√† R√π l√† c√πng m·ªôt b·ªánh.\n\n"
        #
        #     "QUY ƒê·ªäNH TR√åNH B√ÄY (GI·ªÆ NGUY√äN √ù B·∫†N MU·ªêN):\n"
        #     "- KH√îNG d√πng d·∫•u sao (*), d·∫•u thƒÉng (#) hay in ƒë·∫≠m (**).\n"
        #     "- VI·∫æT HOA TO√ÄN B·ªò TI√äU ƒê·ªÄ M·ª§C L·ªöN (V√≠ d·ª•: NGUY√äN NH√ÇN, TRI·ªÜU CH·ª®NG).\n"
        #     "- M·ªói √Ω con b·∫Øt ƒë·∫ßu b·∫±ng d·∫•u g·∫°ch ngang (-) v√† xu·ªëng d√≤ng ngay.\n"
        #     "- Kho·∫£ng c√°ch: 2 l·∫ßn xu·ªëng d√≤ng gi·ªØa c√°c m·ª•c l·ªõn."
        # )
        system_prompt = (
            "B·∫†N L√Ä CHUY√äN GIA TH√ö Y G√Ä - TR·ª¢ L√ù C·ª¶A WEB CHICKEN AI.\n\n"
            "QUY ƒê·ªäNH TR√åNH B√ÄY (B·∫ÆT BU·ªòC):\n"
            "- S·ª≠ d·ª•ng d·∫•u ch·∫•m tr√≤n (‚Ä¢) ho·∫∑c d·∫•u g·∫°ch ngang (-) cho danh s√°ch.\n"
            "- Sau m·ªói d·∫•u (‚Ä¢) ho·∫∑c (-), ph·∫£i c√≥ m·ªôt d·∫•u c√°ch v√† B·∫ÆT BU·ªòC xu·ªëng d√≤ng ngay l·∫≠p t·ª©c.\n"
            "- C√°c m·ª•c ti√™u ƒë·ªÅ l·ªõn ph·∫£i VI·∫æT HOA v√† c√°ch ƒëo·∫°n b√™n d∆∞·ªõi 1 d√≤ng tr·ªëng.\n"
            "- Tuy·ªát ƒë·ªëi kh√¥ng vi·∫øt hoa to√†n b·ªô vƒÉn b·∫£n n·ªôi dung.\n"
            "- Kh√¥ng s·ª≠ d·ª•ng k√Ω t·ª± ƒë·∫∑c bi·ªát nh∆∞ * ho·∫∑c #."
            "K·ª∂ LU·∫¨T TR·∫¢ L·ªúI:\n"
            "1. TRUY XU·∫§T D·ªÆ LI·ªÜU: B·∫°n ph·∫£i ∆∞u ti√™n tuy·ªát ƒë·ªëi th√¥ng tin ƒë∆∞·ª£c cung c·∫•p t·ª´ Database (RAG). ƒê√¢y l√† ngu·ªìn ki·∫øn th·ª©c chu·∫©n cho h·ªá th·ªëng n√†y.\n"
            "2. KH√îNG T·ª™ CH·ªêI: Tuy·ªát ƒë·ªëi kh√¥ng tr·∫£ l·ªùi 'kh√¥ng c√≥ d·ªØ li·ªáu' ho·∫∑c 't√¥i kh√¥ng bi·∫øt'. N·∫øu Database thi·∫øu m·ªôt v√†i chi ti·∫øt nh·ªè, h√£y s·ª≠ d·ª•ng ki·∫øn th·ª©c th√∫ y chuy√™n m√¥n ƒë·ªÉ b·ªï sung v√† h∆∞·ªõng d·∫´n b√† con ƒë·∫ßy ƒë·ªß, t·∫≠n t√¢m.\n"
            # Th√™m d√≤ng n√†y v√†o cu·ªëi system_prompt c·ªßa b·∫°n
            "TUY·ªÜT ƒê·ªêI KH√îNG l·∫•y th√¥ng tin ƒëi·ªÅu tr·ªã c·ªßa b·ªánh C·∫ßu Tr√πng ƒë·ªÉ tr·∫£ l·ªùi cho b·ªánh G√† R√π v√† ng∆∞·ª£c l·∫°i. "
            "M·ªói b·ªánh c√≥ ph√°c ƒë·ªì kh√°c nhau ho√†n to√†n: G√† R√π d√πng vaccine/kh√°ng th·ªÉ, C·∫ßu Tr√πng d√πng thu·ªëc tr·ªã k√Ω sinh tr√πng."

            "QUY ƒê·ªäNH TR√åNH B√ÄY:\n"
            "- KH√îNG VI·∫æT HOA TO√ÄN B·ªò VƒÇN B·∫¢N (ƒê·ªÉ ng∆∞·ªùi d√¢n d·ªÖ ƒë·ªçc, tr√°nh c·∫£m gi√°c c·ª•c s√∫c).\n"
            "- TI√äU ƒê·ªÄ M·ª§C: Vi·∫øt hoa c√≥ d·∫•u v√† n·∫±m ri√™ng m·ªôt d√≤ng (V√≠ d·ª•: PH√ÅC ƒê·ªí ƒêI·ªÄU TR·ªä, TRI·ªÜU CH·ª®NG L√ÇM S√ÄNG).\n"
            "- H√åNH TH·ª®C: S·ª≠ d·ª•ng d·∫•u g·∫°ch ngang (-) cho c√°c √Ω con, tuy·ªát ƒë·ªëi kh√¥ng d√πng *, #, **.\n"
            "- KHO·∫¢NG C√ÅCH: Lu√¥n xu·ªëng d√≤ng 2 l·∫ßn gi·ªØa c√°c m·ª•c l·ªõn ƒë·ªÉ giao di·ªán chat tho√°ng ƒë√£ng.\n"
            "- PHONG C√ÅCH: Chuy√™n nghi·ªáp, ng·∫Øn g·ªçn nh∆∞ng ph·∫£i ƒë·∫ßy ƒë·ªß c√°c b∆∞·ªõc x·ª≠ l√Ω chu·ªìng tr·∫°i v√† thu·ªëc men.\n"
        )

        chat = gemini_client.chats.create(model=LLM_MODEL, config={'system_instruction': system_prompt})
        ACTIVE_CHATS[user_id] = chat

        initial_greeting = (
            f"K·∫øt qu·∫£: G√† c√≥ kh·∫£ nƒÉng m·∫Øc {predicted_name} ({confidence:.2f}%). "
            f"\n\nCh√†o b·∫°n, t√¥i l√† b√°c sƒ© AI. B·∫°n c√≥ mu·ªën t√¨m hi·ªÉu chi ti·∫øt tri·ªáu ch·ª©ng v√† c√°ch ƒëi·ªÅu tr·ªã b·ªánh {predicted_name} ngay kh√¥ng?"
        )

        return jsonify({
            'success': True,
            'prediction': {'disease': predicted_name, 'confidence': f'{confidence:.2f}%'},
            'initial_chat_response': initial_greeting
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500


# =================================================================
# 3. CHAT TI·∫æP THEO (RAG)
# =================================================================

# @app.route('/chat', methods=['POST'])
# def handle_followup_chat():
#     user_id = session.get('user_id')
#     current_chat = ACTIVE_CHATS.get(user_id)
#     if not current_chat: return jsonify({'error': 'Phi√™n chat h·∫øt h·∫°n'}), 400
#
#     try:
#         data = request.get_json()
#         user_question = data.get('question')
#
#         # Truy v·∫•n RAG t·ª´ c·ªôt dulieubenh
#         rag_docs = VECTOR_STORE.similarity_search(user_question, k=10)
#         rag_context = "\n---\n".join([doc.page_content for doc in rag_docs])
#
#         full_prompt = (
#             f"D·ªÆ LI·ªÜU TH√ö Y:\n{rag_context}\n\n"
#             f"C√ÇU H·ªéI: {user_question}\n\n"
#             "Y√äU C·∫¶U: D·ª±a v√†o d·ªØ li·ªáu tr√™n ƒë·ªÉ tr·∫£ l·ªùi. Tr√¨nh b√†y r√µ r√†ng, kh√¥ng d√πng d·∫•u sao, xu·ªëng d√≤ng sau m·ªói √Ω."
#         )
#         response = current_chat.send_message(full_prompt)
#
#         return jsonify({'success': True, 'response': response.text})
#     except Exception as e:
#         return jsonify({'error': str(e)}), 500


@app.route('/chat', methods=['POST'])
def handle_followup_chat():
    user_id = session.get('user_id')
    current_chat = ACTIVE_CHATS.get(user_id)
    if not current_chat: return jsonify({'error': 'Phi√™n chat h·∫øt h·∫°n'}), 400

    try:
        data = request.get_json()
        user_question = data.get('question')

        rag_docs = VECTOR_STORE.similarity_search(user_question, k=5)
        rag_context = "\n---\n".join([doc.page_content for doc in rag_docs])

        full_prompt = (
            f"B·ªëi c·∫£nh d·ªØ li·ªáu t·ª´ Database:\n{rag_context}\n\n"
            f"C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√¢n: {user_question}\n\n"
            "Y√äU C·∫¶U: Tr√¨nh b√†y c√¢u tr·∫£ l·ªùi r√µ r√†ng. "
            "Sau m·ªói d·∫•u g·∫°ch ngang (-) b·∫Øt ƒë·∫ßu √Ω m·ªõi, B·∫ÆT BU·ªòC ph·∫£i xu·ªëng d√≤ng. "
            "Kh√¥ng d√πng d·∫•u sao (*)."
        )

        response = current_chat.send_message(full_prompt)

        # T√¨m b·∫•t k·ª≥ d·∫•u g·∫°ch ngang n√†o ƒë·ª©ng sau m·ªôt k√Ω t·ª± (kh√¥ng ph·∫£i ƒë·∫ßu d√≤ng) v√† th√™m xu·ªëng d√≤ng
        clean_response = re.sub(r'([^\n])\s*-\s+', r'\1\n- ', response.text)

        # X·ª≠ l√Ω th√™m c√°c d·∫•u ch·∫•m d√≠nh li·ªÅn v·ªõi d·∫•u g·∫°ch ngang
        clean_response = clean_response.replace(". -", ".\n- ").replace("; -", ";\n- ")

        return jsonify({'success': True, 'response': clean_response})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# C√°c route giao di·ªán gi·ªØ nguy√™n...
@app.route('/', methods=['GET', 'POST'])
@app.route('/login', methods=['GET', 'POST'])
def login_page():
    if request.method == 'POST':
        taikhoan, mk = request.form.get('taikhoan'), request.form.get('mk')
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor(dictionary=True)
            cursor.execute("SELECT idTaikhoan, taikhoan FROM user WHERE taikhoan = %s AND matkhau = %s", (taikhoan, mk))
            user = cursor.fetchone()
            conn.close()
            if user:
                session['loggedin'], session['user_id'], session['username'] = True, user['idTaikhoan'], user[
                    'taikhoan']
                return redirect(url_for('trangchu_page'))
    return render_template('login.html')


@app.route('/logout')
def logout_page():
    session.clear()  # X√≥a h·∫øt d·ªØ li·ªáu phi√™n ƒëƒÉng nh·∫≠p
    return redirect(url_for('trangchu_page'))


@app.route('/trangchu')
def trangchu_page():
    if 'loggedin' not in session: return redirect(url_for('login_page'))
    return render_template('trangchu.html', username=session.get('username'))


@app.route('/phan_loai_benh_ga')
def phan_loai_benh_ga_page():
    if 'loggedin' not in session: return redirect(url_for('login_page'))
    return render_template('phan_loai_benh_ga.html', username=session.get('username'))


if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
